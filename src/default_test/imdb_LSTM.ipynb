{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aslesani/pgmpy_fork/blob/master/src/default_test/imdb_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OmJrgoGBTfgJ",
        "colab_type": "code",
        "outputId": "39d708de-ab42-4288-bee6-7bcc5970b9b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "'''Trains an LSTM model on the IMDB sentiment classification task.\n",
        "The dataset is actually too small for LSTM to be of any advantage\n",
        "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
        "# Notes\n",
        "- RNNs are tricky. Choice of batch size is important,\n",
        "choice of loss and optimizer is critical, etc.\n",
        "Some configurations won't converge.\n",
        "- LSTM loss decrease patterns during training can be quite different\n",
        "from what you see with CNNs/MLPs/etc.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM, SimpleRNN\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "WJSdFzlqcakL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_train_val_graph(history):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "  print('epochs:' , epochs)\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ChXfRjq4jJko",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_max_len_of_sequences(list_of_sequences):\n",
        "  lengths = [len(list_of_sequences[i]) for i in range(len(list_of_sequences))]\n",
        "  return max(lengths) , min(lengths) , lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P_zUyBhXljmq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_set_of_sensor_events(list_of_sequences):\n",
        " \n",
        "  set_of_sensor_events = set()\n",
        "  \n",
        "  for i in range(len(list_of_sequences)):\n",
        "      set_of_sensor_events = set_of_sensor_events.union(set(list_of_sequences[i]))\n",
        "  \n",
        "  return set_of_sensor_events, len(set_of_sensor_events)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4WTRhBH_XQim",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_data_from_CSV_file(dest_file , data_type ,  has_header = False , return_as_pandas_data_frame = False , remove_date_and_time = False , return_header_separately = False , convert_int_columns_to_int = False):\n",
        "    '''\n",
        "    this function is a replacement for read_data_from_PCA_output_file and read_data_from_PCA_digitized_file\n",
        "    with more capabalities.\n",
        "    \n",
        "    Parameters:\n",
        "    ==========\n",
        "    dest_file: \n",
        "    data_type: type of data that should be read  \n",
        "    has_header = if the file has header, it is set to True. The header is the first line that starts whit '#' character \n",
        "    return_as_pandas_data_frame = if True, the return_value is pandas Dataframe, else numpy ndaaray\n",
        "    \n",
        "    convert_int_columns_to_int: if the user want to keep date and time columns, then she should \n",
        "                                specify data_type as object and then set convert_int_columns_to_int to True\n",
        "    \n",
        "    Returns:\n",
        "    ========\n",
        "    return_value: type of it is pandas Dataframe or numpy ndaaray\n",
        "    \n",
        "    '''\n",
        "    header = \"\"\n",
        "    with open(dest_file,'r') as dest_f:\n",
        "        data_iter = csv.reader(dest_f, \n",
        "                               delimiter = ',')#quotechar = '\"')\n",
        "    \n",
        "        if has_header:\n",
        "            header = next(data_iter)\n",
        "            header[0] = header[0].split('# ')[1] # remove # from first element\n",
        "        \n",
        "        \n",
        "        data = [data for data in data_iter]\n",
        "    \n",
        "    if remove_date_and_time:\n",
        "        data = np.delete(np.delete(data, -1, 1), -1 , 1)\n",
        "\n",
        "    return_value= np.asarray(data, dtype = data_type)\n",
        "    \n",
        "    if convert_int_columns_to_int:\n",
        "        rows , cols_to_convert = np.shape(return_value)\n",
        "        \n",
        "        if remove_date_and_time == False:\n",
        "            cols_to_convert -=2\n",
        "        \n",
        "        for r in range(rows):\n",
        "            for c in range(cols_to_convert):\n",
        "                return_value[r,c] = int(return_value[r,c])\n",
        "        \n",
        "    \n",
        "    if return_as_pandas_data_frame:\n",
        "        return_value = pd.DataFrame(return_value , columns = header)\n",
        "        \n",
        "    if return_header_separately:\n",
        "        return header , return_value\n",
        "    \n",
        "    else:   \n",
        "        return return_value\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSnIdgbbWlm6",
        "colab_type": "code",
        "outputId": "fafa8eb3-bf07-40db-c168-948bf988ded0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aslesani/pgmpy_fork.git\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pgmpy_fork'...\n",
            "remote: Enumerating objects: 202, done.\u001b[K\n",
            "remote: Counting objects: 100% (202/202), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 971 (delta 97), reused 146 (delta 63), pack-reused 769\u001b[K\n",
            "Receiving objects: 100% (971/971), 562.13 KiB | 8.92 MiB/s, done.\n",
            "Resolving deltas: 100% (527/527), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "knS7nVmkLiMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "820156b1-9634-40b5-a310-3d00e080f72a"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zie8KaEFZ48Y",
        "colab_type": "code",
        "outputId": "3624e0b6-bfd7-40a5-a564-84a8576cd955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aslesani/created_dataset.git"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'created_dataset'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/90)   \u001b[K\rremote: Counting objects:   2% (2/90)   \u001b[K\rremote: Counting objects:   3% (3/90)   \u001b[K\rremote: Counting objects:   4% (4/90)   \u001b[K\rremote: Counting objects:   5% (5/90)   \u001b[K\rremote: Counting objects:   6% (6/90)   \u001b[K\rremote: Counting objects:   7% (7/90)   \u001b[K\rremote: Counting objects:   8% (8/90)   \u001b[K\rremote: Counting objects:  10% (9/90)   \u001b[K\rremote: Counting objects:  11% (10/90)   \u001b[K\rremote: Counting objects:  12% (11/90)   \u001b[K\rremote: Counting objects:  13% (12/90)   \u001b[K\rremote: Counting objects:  14% (13/90)   \u001b[K\rremote: Counting objects:  15% (14/90)   \u001b[K\rremote: Counting objects:  16% (15/90)   \u001b[K\rremote: Counting objects:  17% (16/90)   \u001b[K\rremote: Counting objects:  18% (17/90)   \u001b[K\rremote: Counting objects:  20% (18/90)   \u001b[K\rremote: Counting objects:  21% (19/90)   \u001b[K\rremote: Counting objects:  22% (20/90)   \u001b[K\rremote: Counting objects:  23% (21/90)   \u001b[K\rremote: Counting objects:  24% (22/90)   \u001b[K\rremote: Counting objects:  25% (23/90)   \rremote: Counting objects:  26% (24/90)   \u001b[K\rremote: Counting objects:  27% (25/90)   \u001b[K\rremote: Counting objects:  28% (26/90)   \u001b[K\rremote: Counting objects:  30% (27/90)   \u001b[K\rremote: Counting objects:  31% (28/90)   \u001b[K\rremote: Counting objects:  32% (29/90)   \u001b[K\rremote: Counting objects:  33% (30/90)   \u001b[K\rremote: Counting objects:  34% (31/90)   \u001b[K\rremote: Counting objects:  35% (32/90)   \u001b[K\rremote: Counting objects:  36% (33/90)   \u001b[K\rremote: Counting objects:  37% (34/90)   \u001b[K\rremote: Counting objects:  38% (35/90)   \u001b[K\rremote: Counting objects:  40% (36/90)   \u001b[K\rremote: Counting objects:  41% (37/90)   \u001b[K\rremote: Counting objects:  42% (38/90)   \u001b[K\rremote: Counting objects:  43% (39/90)   \u001b[K\rremote: Counting objects:  44% (40/90)   \u001b[K\rremote: Counting objects:  45% (41/90)   \u001b[K\rremote: Counting objects:  46% (42/90)   \u001b[K\rremote: Counting objects:  47% (43/90)   \u001b[K\rremote: Counting objects:  48% (44/90)   \u001b[K\rremote: Counting objects:  50% (45/90)   \u001b[K\rremote: Counting objects:  51% (46/90)   \u001b[K\rremote: Counting objects:  52% (47/90)   \u001b[K\rremote: Counting objects:  53% (48/90)   \u001b[K\rremote: Counting objects:  54% (49/90)   \u001b[K\rremote: Counting objects:  55% (50/90)   \u001b[K\rremote: Counting objects:  56% (51/90)   \u001b[K\rremote: Counting objects:  57% (52/90)   \u001b[K\rremote: Counting objects:  58% (53/90)   \u001b[K\rremote: Counting objects:  60% (54/90)   \u001b[K\rremote: Counting objects:  61% (55/90)   \u001b[K\rremote: Counting objects:  62% (56/90)   \u001b[K\rremote: Counting objects:  63% (57/90)   \u001b[K\rremote: Counting objects:  64% (58/90)   \u001b[K\rremote: Counting objects:  65% (59/90)   \u001b[K\rremote: Counting objects:  66% (60/90)   \u001b[K\rremote: Counting objects:  67% (61/90)   \u001b[K\rremote: Counting objects:  68% (62/90)   \u001b[K\rremote: Counting objects:  70% (63/90)   \u001b[K\rremote: Counting objects:  71% (64/90)   \u001b[K\rremote: Counting objects:  72% (65/90)   \u001b[K\rremote: Counting objects:  73% (66/90)   \u001b[K\rremote: Counting objects:  74% (67/90)   \u001b[K\rremote: Counting objects:  75% (68/90)   \u001b[K\rremote: Counting objects:  76% (69/90)   \u001b[K\rremote: Counting objects:  77% (70/90)   \u001b[K\rremote: Counting objects:  78% (71/90)   \u001b[K\rremote: Counting objects:  80% (72/90)   \u001b[K\rremote: Counting objects:  81% (73/90)   \u001b[K\rremote: Counting objects:  82% (74/90)   \u001b[K\rremote: Counting objects:  83% (75/90)   \u001b[K\rremote: Counting objects:  84% (76/90)   \u001b[K\rremote: Counting objects:  85% (77/90)   \u001b[K\rremote: Counting objects:  86% (78/90)   \u001b[K\rremote: Counting objects:  87% (79/90)   \u001b[K\rremote: Counting objects:  88% (80/90)   \u001b[K\rremote: Counting objects:  90% (81/90)   \u001b[K\rremote: Counting objects:  91% (82/90)   \u001b[K\rremote: Counting objects:  92% (83/90)   \u001b[K\rremote: Counting objects:  93% (84/90)   \u001b[K\rremote: Counting objects:  94% (85/90)   \u001b[K\rremote: Counting objects:  95% (86/90)   \u001b[K\rremote: Counting objects:  96% (87/90)   \u001b[K\rremote: Counting objects:  97% (88/90)   \u001b[K\rremote: Counting objects:  98% (89/90)   \u001b[K\rremote: Counting objects: 100% (90/90)   \u001b[K\rremote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 90 (delta 75), reused 90 (delta 75), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9RLVnu1PzZYL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r pgmpy_fork  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sRITYv2ydN4l",
        "colab_type": "code",
        "outputId": "aca9b337-74f9-429f-9d39-8bbcf2b55ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd pgmpy_fork/src/default_test"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pgmpy_fork/src/default_test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NTlOaB_q0Q4d",
        "colab_type": "code",
        "outputId": "c1cd027f-01eb-4993-a2e6-0a0c953edefc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sEOEuH82dXy6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cxg1eVsVTF6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_binary_classes_to_zero_and_one(data):\n",
        "  \n",
        "  values = sorted(list(set(data)))\n",
        "  for i in range(len(data)):\n",
        "    data[i] = values.index(data[i])\n",
        "\n",
        "    \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E8ow8BydTfJ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "735fbfee-af00-480c-dddb-5d67ad0e8911"
      },
      "cell_type": "code",
      "source": [
        "def test_convert_binary_classes_to_zero_and_one():\n",
        "  data = [2,1,1,1,2]\n",
        "  data = convert_binary_classes_to_zero_and_one(data)\n",
        "  print(data)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 0, 0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Adhup5wx35Il",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def mcor(y_true, y_pred):\n",
        "    #matthews_correlation\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        " \n",
        " \n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos\n",
        " \n",
        " \n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    tn = K.sum(y_neg * y_pred_neg)\n",
        " \n",
        " \n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg)\n",
        " \n",
        " \n",
        "    numerator = (tp * tn - fp * fn)\n",
        "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        " \n",
        " \n",
        "    return numerator / (denominator + K.epsilon())\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w0em365aEiF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c94c0dd6-1e9f-484d-e710-5a7a07f62720"
      },
      "cell_type": "code",
      "source": [
        "!pip install tabulate "
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (0.8.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wRPxCWPzExrc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a2e3e2fd-0584-40cc-ac2e-ca74216c0867"
      },
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "print(tabulate([['Alice1111111111111111111111111111111111', 24], ['Bob', 19]], headers=['algorithm', 'acc']))\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "algorithm                                  acc\n",
            "---------------------------------------  -----\n",
            "Alice1111111111111111111111111111111111     24\n",
            "Bob                                         19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cM2IkLSSM458",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imdb_lstm_data_preparation(max_features = 20000, maxlen = 80):\n",
        "  #max_features = 20000#number_of_events\n",
        "  # cut texts after this number of words (among top max_features most common words)\n",
        "  #maxlen = 10#max_seq_len\n",
        "\n",
        "  print('Loading data...')\n",
        "  (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "  print(len(x_train), 'train sequences')\n",
        "  print(len(x_test), 'test sequences')\n",
        "\n",
        "  #print('before apply pad_sequence, x_train[0]:' , x_train[0])\n",
        "\n",
        "  print('Pad sequences (samples x time)')\n",
        "  x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "  x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "  print('x_train shape:', x_train.shape)\n",
        "  print('x_test shape:', x_test.shape)\n",
        "  \n",
        "  return x_train, x_test, y_train, y_test, max_features, maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOY7VRWGN0tY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from read_write import read_sequence_of_bags_CSV_file_with_activity, read_sequence_based_CSV_file_with_activity, read_data_from_CSV_file\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def my_data_preparation(address_to_read):\n",
        "  \n",
        "  list_of_data , list_of_persons , _ = read_sequence_based_CSV_file_with_activity(file_address = address_to_read, has_header = True , separate_data_based_on_persons = False, separate_words= False)\n",
        "  #sensor_events , number_of_events = get_set_of_sensor_events(sequences)\n",
        "  \n",
        "  list_of_persons = convert_binary_classes_to_zero_and_one(list_of_persons)\n",
        "  \n",
        "  tokenizer = Tokenizer(num_words = 122, filters='!\"#$%&()*+,-./:;<=>?@[\\]^`{|}~')\n",
        "  #list_of_data = [r'salam man', r\"'M38_off' , 'M38_on'\"]\n",
        "  tokenizer.fit_on_texts(list_of_data)\n",
        "  sequences = tokenizer.texts_to_sequences(list_of_data)\n",
        "  \n",
        "  max_features = 121#number_of_events\n",
        "  # cut texts after this number of words (among top max_features most common words)\n",
        "  maxlen = 10#80#max_seq_len\n",
        "\n",
        "  #print('before apply pad_sequence, x_train[0]:' , x_train[0])\n",
        "\n",
        "  #80% of data for train and 20% for test\n",
        "  train_numbers = int(0.8 * len(sequences))\n",
        "  x_train, y_train = sequences[0: train_numbers] , list_of_persons[0:train_numbers]\n",
        "  x_test, y_test = sequences[train_numbers+1:] , list_of_persons[train_numbers+1:]\n",
        "\n",
        "  print('Pad sequences (samples x time)')\n",
        "  x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "  x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "  print('x_train shape:', x_train.shape)\n",
        "  print('x_test shape:', x_test.shape)\n",
        "\n",
        "  return x_train, x_test, y_train, y_test, max_features, maxlen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Npd2VghtklVO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#! cd pgmpy_fork/src/default_test\n",
        "#!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jzNNJ1TiJSJ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/pgmpy/pgmpy \n",
        "cd ..\n",
        "#!ls\n",
        "#!cd pgmpy/\n",
        "#pip install -r requirements.txt\n",
        "#!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMsynyAJJCnJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d3slldw0XXSC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mydata = read_data_from_CSV_file(dest_file = address_to_save , data_type = int ,  has_header = False , return_as_pandas_data_frame = False , remove_date_and_time = True , return_header_separately = False , convert_int_columns_to_int = True)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFSdJslP4bJQ",
        "colab_type": "code",
        "outputId": "b6eb0ce9-d3da-46c8-c486-5a20639a3cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_seq_len, min_seq_len , lens = get_max_len_of_sequences(sequences)\n",
        "print(max_seq_len, min_seq_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2216 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bUbyz1O5TtEV",
        "colab_type": "code",
        "outputId": "fe5bdddd-33a3-4b28-94f0-d6de4758ee37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "address_to_read= r\"created_dataset/Seq of sensor events_based on activities/based_on_activities.csv\"\n",
        "\n",
        "#x_train, x_test, y_train, y_test, max_features, maxlen = imdb_lstm_data_preparation(maxlen=10)\n",
        "#my_x_train, my_x_test, my_y_train, my_y_test, my_max_features, my_maxlen = my_data_preparation(address_to_read)\n",
        "x_train, x_test, y_train, y_test, max_features, maxlen = my_data_preparation(address_to_read)#imdb_lstm_data_preparation(maxlen=10)\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (2572, 10)\n",
            "x_test shape: (643, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EITeYNgVRqNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40a31c91-ad62-4182-aab3-29651e83eae8"
      },
      "cell_type": "code",
      "source": [
        "print(set(y_train))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ladLQfIuRfdm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train[0:2500]\n",
        "y_train = y_train[0:2500]\n",
        "x_test = x_test[2501:3200]\n",
        "y_test = y_test[2501:3200]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y7Xg1Rd7SvYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = y_train.tolist()\n",
        "y_test = y_test.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZaeKy5XuUss0",
        "colab_type": "code",
        "outputId": "98be588a-f67e-486e-9e41-d7bda043b8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "print((y_train[0:10]))\n",
        "print((my_x_train[0:10]))\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "[[42 46 43 41 42 46 43 41 31 46]\n",
            " [ 9 29 13  9 57 61 13 58 30 62]\n",
            " [16 15 16 15 15 16 15 16 15 16]\n",
            " [ 2  2  1  2  1  2  1  2  1  2]\n",
            " [10  7 11  8  7  8  7  8  7  8]\n",
            " [30 61 13 62 66  1 33 65  2 34]\n",
            " [ 3 19  4  3  4  3 15 24 16  4]\n",
            " [ 2  2  1  2  1  2  2  1  2  1]\n",
            " [ 7  8 10  7  8 11  7  8  7  8]\n",
            " [61 13 62 58  7 66 65  8  7 62]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BsUaDYDeTx3t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model_and_apply_on_data(x_train, y_train,x_test, y_test, max_features,embedding_vector_dim = 64, batch_size = 32, epochs = 5, \n",
        "                                   loss = 'binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'], plot_train_val_graph = False):\n",
        "  \n",
        "  #batch_size = 32\n",
        "\n",
        "  print('Build model...')\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(max_features+1, embedding_vector_dim))\n",
        "  model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "  model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "  model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  # try using different optimizers and different optimizer configs\n",
        "  model.compile(loss= loss,\n",
        "                optimizer=optimizer,\n",
        "                metrics= metrics)#, mcor,recall, f1])\n",
        "\n",
        "  print('Train...')\n",
        "  history = model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test))\n",
        "  score, acc = model.evaluate(x_test, y_test,\n",
        "                              batch_size=batch_size)\n",
        "  print('Test score:', score)# i think score is loss value\n",
        "  print('Test accuracy:', acc)\n",
        " \n",
        "  if plot_train_val_graph:\n",
        "      plot_train_val_graph(history)\n",
        "      \n",
        "  return score, acc, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pCbjPxvEJUD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "1b98295d-9dc0-4696-994b-2b1ccaa0f461"
      },
      "cell_type": "code",
      "source": [
        "create_model_and_apply_on_data(x_train, y_train,x_test, y_test, max_features)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_24 (Embedding)     (None, None, 64)          7808      \n",
            "_________________________________________________________________\n",
            "simple_rnn_23 (SimpleRNN)    (None, None, 64)          8256      \n",
            "_________________________________________________________________\n",
            "simple_rnn_24 (SimpleRNN)    (None, None, 64)          8256      \n",
            "_________________________________________________________________\n",
            "simple_rnn_25 (SimpleRNN)    (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 32,641\n",
            "Trainable params: 32,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train...\n",
            "Train on 2572 samples, validate on 643 samples\n",
            "Epoch 1/5\n",
            "2572/2572 [==============================] - 5s 2ms/step - loss: 0.3826 - acc: 0.8674 - val_loss: 1.8903 - val_acc: 0.3437\n",
            "Epoch 2/5\n",
            "2572/2572 [==============================] - 1s 364us/step - loss: 0.3252 - acc: 0.8857 - val_loss: 1.1303 - val_acc: 0.3577\n",
            "Epoch 3/5\n",
            "2572/2572 [==============================] - 1s 367us/step - loss: 0.1921 - acc: 0.9172 - val_loss: 0.8259 - val_acc: 0.7232\n",
            "Epoch 4/5\n",
            "2572/2572 [==============================] - 1s 366us/step - loss: 0.1383 - acc: 0.9440 - val_loss: 1.2959 - val_acc: 0.5101\n",
            "Epoch 5/5\n",
            "2572/2572 [==============================] - 1s 366us/step - loss: 0.1337 - acc: 0.9456 - val_loss: 1.0362 - val_acc: 0.6874\n",
            "643/643 [==============================] - 0s 138us/step\n",
            "Test score: 1.0361589256378578\n",
            "Test accuracy: 0.6874027994706138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rhnw6Y4kQbIz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings = model.layers[0].get_weights()[0]\n",
        "print(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-f6NjJlkJFod",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.layers[1]."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HPT1K2r9RsFo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# `word_to_index` is a mapping (i.e. dict) from words to their index, e.g. `love`: 69\n",
        "words_embeddings = {w:embeddings[idx] for w, idx in word_to_index.items()}\n",
        "\n",
        "# now you can use it like this for example\n",
        "print(words_embeddings['love'])  # possible output: [0.21, 0.56, ..., 0.65, 0.10]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yhQ1x75KbI19",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(type(score) , type(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "au02di-ubMqE",
        "colab_type": "code",
        "outputId": "a68cff59-1a0f-42a6-888b-3ef89722c2ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs: range(1, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nISwiImIQhbCIiIhB/h/2dgmoNBKbfAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "v6qlruTYcrfl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}