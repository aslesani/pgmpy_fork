{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aslesani/pgmpy_fork/blob/master/src/default_test/imdb_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OmJrgoGBTfgJ",
    "outputId": "39d708de-ab42-4288-bee6-7bcc5970b9b4"
   },
   "outputs": [],
   "source": [
    "'''Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "# Notes\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "from read_write import data_preparation_for_sequences_based_deep_models, convert_binary_classes_to_zero_and_one\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score , recall_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJSdFzlqcakL"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_val_graph(history):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  epochs = range(1, len(loss) + 1)\n",
    "  print('epochs:' , epochs)\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChXfRjq4jJko"
   },
   "outputs": [],
   "source": [
    "def get_max_len_of_sequences(list_of_sequences):\n",
    "  lengths = [len(list_of_sequences[i]) for i in range(len(list_of_sequences))]\n",
    "  return max(lengths) , min(lengths) , lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_zUyBhXljmq"
   },
   "outputs": [],
   "source": [
    "def get_set_of_sensor_events(list_of_sequences):\n",
    " \n",
    "  set_of_sensor_events = set()\n",
    "  \n",
    "  for i in range(len(list_of_sequences)):\n",
    "      set_of_sensor_events = set_of_sensor_events.union(set(list_of_sequences[i]))\n",
    "  \n",
    "  return set_of_sensor_events, len(set_of_sensor_events)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "PSnIdgbbWlm6",
    "outputId": "fafa8eb3-bf07-40db-c168-948bf988ded0"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/aslesani/pgmpy_fork.git\n",
    "#ls\n",
    "#!git clone https://github.com/aslesani/created_dataset.git\n",
    "#!rm -r pgmpy_fork  \n",
    "#cd pgmpy_fork/src/default_test\n",
    "#cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Adhup5wx35Il"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def mcor(y_true, y_pred):\n",
    "    #matthews_correlation\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    " \n",
    " \n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    " \n",
    " \n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    " \n",
    " \n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    " \n",
    " \n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    " \n",
    " \n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def f1_skl(y_true, y_pred):\n",
    "    f1_score_micro = f1_score(y_true, y_pred, average='micro') \n",
    "    return f1_score_micro\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([0, 1, 2, 0, 1, 2])\n",
    "y_pred = np.array([0, 2, 1, 0, 0, 1])\n",
    "#print(f1(y_true,y_pred))\n",
    "print(f1_skl(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w0em365aEiF1",
    "outputId": "c94c0dd6-1e9f-484d-e710-5a7a07f62720"
   },
   "outputs": [],
   "source": [
    "#!pip install tabulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "wRPxCWPzExrc",
    "outputId": "a2e3e2fd-0584-40cc-ac2e-ca74216c0867"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "#print(tabulate([['Alice', 24], ['Bob', 19]], headers=['algorithm', 'acc']))\n",
    "\n",
    "def print_list_of_lists(data , headers):\n",
    "    print(tabulate(data, headers=headers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_print_list_of_lists():\n",
    "    data = [['Alice', 24], ['Bob', 19]]\n",
    "    headers=['algorithm', 'acc']\n",
    "    print_list_of_lists(data , headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm      acc\n",
      "-----------  -----\n",
      "Alice           24\n",
      "Bob             19\n"
     ]
    }
   ],
   "source": [
    "test_print_list_of_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cM2IkLSSM458"
   },
   "outputs": [],
   "source": [
    "def imdb_lstm_data_preparation(max_features = 20000, maxlen = 80):\n",
    "  #max_features = 20000#number_of_events\n",
    "  # cut texts after this number of words (among top max_features most common words)\n",
    "  #maxlen = 10#max_seq_len\n",
    "\n",
    "  print('Loading data...')\n",
    "  (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "  print(len(x_train), 'train sequences')\n",
    "  print(len(x_test), 'test sequences')\n",
    "\n",
    "  #print('before apply pad_sequence, x_train[0]:' , x_train[0])\n",
    "\n",
    "  print('Pad sequences (samples x time)')\n",
    "  x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "  x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "  print('x_train shape:', x_train.shape)\n",
    "  print('x_test shape:', x_test.shape)\n",
    "  \n",
    "  return x_train, x_test, y_train, y_test, max_features, maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Npd2VghtklVO"
   },
   "outputs": [],
   "source": [
    "#! cd pgmpy_fork/src/default_test\n",
    "#!ls\n",
    "#!git clone https://github.com/pgmpy/pgmpy \n",
    "#cd ..\n",
    "#!ls\n",
    "#!cd pgmpy/\n",
    "#pip install -r requirements.txt\n",
    "#!python setup.py install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lstm_without_embedding(x_train, y_train,x_test, y_test, max_features,embedding_vector_dim = 64, batch_size = 32, epochs = 5, \n",
    "                                   loss = 'binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'], plot_train_val_graph = False):\n",
    "  \n",
    "  #batch_size = 32\n",
    "\n",
    "  print('Build model...')\n",
    "  model = Sequential()\n",
    "  #model.add(Embedding(max_features+1, embedding_vector_dim))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  # try using different optimizers and different optimizer configs\n",
    "  model.compile(loss= loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics= metrics)#, mcor,recall, f1])\n",
    "\n",
    "  print('Train...')\n",
    "  history = model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test))\n",
    "  score, acc = model.evaluate(x_test, y_test,\n",
    "                              batch_size=batch_size)\n",
    "  print('Test score:', score)# i think score is loss value\n",
    "  print('Test accuracy:', acc)\n",
    " \n",
    "  if plot_train_val_graph:\n",
    "      plot_train_val_graph(history)\n",
    "      \n",
    "  return score, acc, history, len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsUaDYDeTx3t"
   },
   "outputs": [],
   "source": [
    "def create_model_and_apply_on_data(x_train, y_train,x_test, y_test, max_features,\n",
    "                                   embedding_vector_dim = 64, batch_size = 32, epochs = 3, \n",
    "                                   loss = 'binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'], \n",
    "                                   plot_trainvalgraph = True,\n",
    "                                   number_of_lstm_layers = 1,\n",
    "                                   ID_of_layer_to_repeat = 0):\n",
    "  '''\n",
    "  Parameters:\n",
    "  ===============\n",
    "  number_of_lstm_layers (default value = 1)\n",
    "      indicate the number of layers in stack of layers\n",
    "  \n",
    "  ID_of_layer_to_repeat (default value = 0)\n",
    "     0: LSTM\n",
    "     1:RNN\n",
    "     2: GRU\n",
    "  \n",
    "  '''\n",
    "  #batch_size = 32\n",
    "\n",
    "  print('Build model...')\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(max_features+1, embedding_vector_dim))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  \n",
    "  layer_names = [LSTM, SimpleRNN, GRU]\n",
    "  if number_of_lstm_layers > 1:\n",
    "        for l in range(number_of_lstm_layers-1):\n",
    "            model.add(layer_names[ID_of_layer_to_repeat](64, dropout=0.2, recurrent_dropout=0.2, return_sequences = True))\n",
    "  model.add(layer_names[ID_of_layer_to_repeat](64, dropout=0.2, recurrent_dropout=0.2))\n",
    "        \n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  # try using different optimizers and different optimizer configs\n",
    "  model.compile(loss= loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics= [f1])#metrics, mcor,recall, f1])\n",
    "\n",
    "  print('Train...')\n",
    "  history = model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test))\n",
    "  score, acc = model.evaluate(x_test, y_test,\n",
    "                              batch_size=batch_size)\n",
    "  #print('Test score:', score)# i think score is loss value\n",
    "  #print('Test accuracy:', acc)\n",
    " \n",
    "  #print(model.layers[0].output)\n",
    "  if plot_trainvalgraph:\n",
    "      plot_train_val_graph(history)\n",
    "      \n",
    "  return score, acc, history, len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMsynyAJJCnJ"
   },
   "outputs": [],
   "source": [
    "def select_hyperparameters(address_to_read, ID_of_layer_to_repeat, hasActivitycol):\n",
    "    #address_to_read= r\"E:/pgmpy/Seq of sensor events_based on activities/based_on_activities.csv\"\n",
    "    #address_to_read = r\"E:\\pgmpy\\Seq of sensor events_no overlap_based on different deltas\\delta_{}min.csv\"\n",
    "    #address_to_read = r\"E:\\pgmpy\\Seq of sensor events_based_on_activity_and_no_overlap_delta\\delta_{}min.csv\"\n",
    "    \n",
    "    for layers in range(2,5):\n",
    "        print(\"number_of_lstm_layers:\" , layers)\n",
    "\n",
    "        results = []\n",
    "        for delta in [15]:#list(range(1,10)):# + [30,45,60,75,90,100]:#, 120,150, 180,200,240,300,400,500,600,700,800,900,1000]: #:\n",
    "            print(\"delta:\" , delta)\n",
    "            x_train, x_test, y_train, y_test, max_features, maxlen = data_preparation_for_sequences_based_deep_models(address_to_read = address_to_read.format(delta),\n",
    "                                                                                                                  number_of_words = 122, \n",
    "                                                                                                                  max_seq_len = 20,\n",
    "                                                                                                                  hasActivitycol= hasActivitycol)\n",
    "            test_score, test_acc, history, num_of_train_samples, num_of_test_sample = create_model_and_apply_on_data(x_train =x_train, \n",
    "                                                                                                y_train = y_train,\n",
    "                                                                                                x_test = x_test, \n",
    "                                                                                                y_test = y_test, \n",
    "                                                                                                max_features = max_features,\n",
    "                                                                                                number_of_lstm_layers = layers,\n",
    "                                                                                                ID_of_layer_to_repeat = ID_of_layer_to_repeat )\n",
    "            results.append([delta, \n",
    "                        num_of_train_samples, \n",
    "                        num_of_test_sample, \n",
    "                        history.history['loss'][-1], \n",
    "                        history.history['f1'][-1] ,\n",
    "                        test_score, \n",
    "                        test_acc])#, history.history\n",
    "        #print(history.history)\n",
    "        print_list_of_lists(results, ['delta(min)' ,\n",
    "                                  '#train', \n",
    "                                  '#test', \n",
    "                                  'train loss(last)', \n",
    "                                  'train_f1(last)', \n",
    "                                  'val loss ', \n",
    "                                  'val f1', ])#'history'\n",
    "        print(\"results:\", results)\n",
    "        #print(\"results[:][-1]:\", results[:][-1])\n",
    "        #best_val_acc_index = np.argmax(results[:][-1])\n",
    "        #print(\"****************************************\")\n",
    "        #print(\"best vlidation acc delta:\" , results[best_val_acc_index][0])\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\pgmpy\\Twor2009\\Seq of sensor events_no overlap_based on different deltas\\delta_{}min.csv\n",
      "ID_of_layer_to_repeat: 0\n",
      "number_of_lstm_layers: 2\n",
      "delta: 15\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2134, 20)\n",
      "x_test shape: (533, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_52 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 2134 samples, validate on 533 samples\n",
      "Epoch 1/3\n",
      "2134/2134 [==============================] - 24s 11ms/step - loss: 0.2731 - f1: 0.8298 - val_loss: 0.1329 - val_f1: 0.9824\n",
      "Epoch 2/3\n",
      "2134/2134 [==============================] - 5s 2ms/step - loss: 0.1678 - f1: 0.9230 - val_loss: 0.1558 - val_f1: 0.9613\n",
      "Epoch 3/3\n",
      "2134/2134 [==============================] - 5s 2ms/step - loss: 0.1521 - f1: 0.9310 - val_loss: 0.1352 - val_f1: 0.9673\n",
      "533/533 [==============================] - 0s 505us/step\n",
      "epochs: range(1, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt4FuWd//H3hwAiBwURqwURrFblECFGxIriaS3qitVaBaEeVpdqa9tdt73KT90e6HqtK25Laf31J9ut21aUWrtaa7XUWrbWdgXCUQERRNSIlYOCIigGvr8/ZpI8SZ4kT0IOkPm8ritXnmfue+b5PpPJd2bue+YeRQRmZpYNndo7ADMzaztO+mZmGeKkb2aWIU76ZmYZ4qRvZpYhTvpmZhnipG9NIqlI0nZJA1uybnuSdIykFr92WdK5ktbnvF8t6fRC6jbjs34k6Zbmzt/Acv9F0n+19HKt/XRu7wCsdUnanvO2O/ABsDt9/7mImN2U5UXEbqBnS9fNgog4riWWI+l6YHJEnJmz7OtbYtnW8Tnpd3ARUZV00yPJ6yPi9/XVl9Q5IiraIjYza3tu3sm49PT955IekPQuMFnSqZKelbRV0huSZkrqktbvLCkkDUrf35eWPyHpXUn/K2lwU+um5edLelHSNknfl/RnSdfUE3chMX5O0lpJb0uamTNvkaTvStoi6SVgXAPr5zZJc2pNu1vSd9LX10talX6fl9Kj8PqWVS7pzPR1d0k/S2NbAZyU53PXpctdIWl8On048APg9LTpbHPOuv1mzvw3pN99i6RHJB1RyLppjKRPpfFslfQHScfllN0iaYOkdyS9kPNdR0tanE5/U9L0Qj/PWkFE+CcjP8B64Nxa0/4F2AVcRHIQcCBwMnAKyZng0cCLwE1p/c5AAIPS9/cBm4FSoAvwc+C+ZtQ9DHgXuDgtuxn4ELimnu9SSIy/Ag4GBgFvVX534CZgBTAA6As8nfwr5P2co4HtQI+cZW8EStP3F6V1BJwN7ASK07JzgfU5yyoHzkxf3wX8D9AHOApYWavu5cAR6d/kyjSGj6Rl1wP/UyvO+4Bvpq/PS2McAXQD/i/wh0LWTZ7v/y/Af6WvT0jjODv9G92SrvcuwFDgFeDwtO5g4Oj09UJgYvq6F3BKe/8vZPnHR/oG8ExE/Doi9kTEzohYGBHzI6IiItYBs4CxDcz/UESURcSHwGySZNPUun8LLI2IX6Vl3yXZQeRVYIz/GhHbImI9SYKt/KzLge9GRHlEbAHuaOBz1gHPk+yMAP4G2BoRZWn5ryNiXST+ADwF5O2sreVy4F8i4u2IeIXk6D33cx+MiDfSv8n9JDvs0gKWCzAJ+FFELI2I94GpwFhJA3Lq1LduGjIBeDQi/pD+je4ADiLZ+VaQ7GCGpk2EL6frDpKd97GS+kbEuxExv8DvYa3ASd8AXst9I+l4Sb+R9FdJ7wDTgEMbmP+vOa930HDnbX11P5obR0QEyZFxXgXGWNBnkRyhNuR+YGL6+kqSnVVlHH8rab6ktyRtJTnKbmhdVTqioRgkXSNpWdqMshU4vsDlQvL9qpYXEe8AbwP9c+o05W9W33L3kPyN+kfEauCfSP4OG9PmwsPTqtcCQ4DVkhZIuqDA72GtwEnfIDndz3UPydHtMRFxEPB1kuaL1vQGSXMLAJJEzSRV297E+AZwZM77xi4p/TlwbnqkfDHJTgBJBwIPAf9K0vTSG/hdgXH8tb4YJB0N/BC4EeibLveFnOU2dnnpBpImo8rl9SJpRnq9gLiastxOJH+z1wEi4r6IOI2kaaeIZL0QEasjYgJJE96/A7+U1G0vY7FmctK3fHoB24D3JJ0AfK4NPvMxoETSRZI6A18G+rVSjA8C/yCpv6S+wNcaqhwRbwLPAPcCqyNiTVp0ANAV2ATslvS3wDlNiOEWSb2V3MdwU05ZT5LEvolk/3c9yZF+pTeBAZUd13k8AFwnqVjSASTJ908RUe+ZUxNiHi/pzPSzv0rSDzNf0gmSzko/b2f6s5vkC3xW0qHpmcG29Lvt2ctYrJmc9C2ffwKuJvmHvofkSLdVpYn1CuA7wBbgY8ASkvsKWjrGH5K0vT9H0sn4UAHz3E/SMXt/TsxbgX8EHibpDL2MZOdViG+QnHGsB54Afpqz3OXATGBBWud4ILcd/ElgDfCmpNxmmsr5f0vSzPJwOv9Aknb+vRIRK0jW+Q9JdkjjgPFp+/4BwJ0k/TB/JTmzuC2d9QJglZKrw+4CroiIXXsbjzWPkqZTs32LpCKS5oTLIuJP7R2PWUfhI33bZ0gaJ+ngtIngn0muCFnQzmGZdSgFJf30n3F1ejPH1DzlN0taKWm5pKck5Xb23JnezLFKyQ00rd0haPuvMcA6kiaCccCnIqK+5h0za4ZGm3fS0+wXSa5PLqf6RouVOXXOAuZHxA5JN5LcgHKFpE8A04Ez0qrPAP8nIv6nxb+JmZk1qpAj/VHA2vQGlF3AHKpvVAEgIuZFxI707bNUX3oXJDdsdCXp6OlCcuWBmZm1g0IGXOtPzZtIyknuwKvPdSRXIxAR/ytpHskVBAJ+EBGras8gaQowBaBHjx4nHX/88bWrmJlZAxYtWrQ5Ihq6zBkoLOnna4PP2yYkaTLJreJj0/fHkIzXUXnk/6SkMyLi6RoLi5hFchs9paWlUVZWVkBYZmZWSVJjd5YDhTXvlFPzzsEBJJfS1f7Ac4FbSa7brex8uwR4NiK2R8R2kjOA0YUEZmZmLa+QpL+QZLCkwZK6kg66lFtB0kiSG2TGR8TGnKJXSQZ66pzewTcWqNO8Y2ZmbaPRpB/JAzVuAuaSJOwHI2KFpGmVY3yTXKHTE/iFpKWSKncKDwEvkdz5uAxYFhG/bukvYWZmhdnn7sh1m75Z2/rwww8pLy/n/fffb+9QrADdunVjwIABdOlSc+glSYsiotHht/24RLOMKy8vp1evXgwaNAjfO7lviwi2bNlCeXk5gwcPbnyGPDrMMAyzZ8OgQdCpU/J7dpMe922WXe+//z59+/Z1wt8PSKJv3757dVbWIY70Z8+GKVNgR3p72CuvJO8BJu312IJmHZ8T/v5jb/9WHeJI/9ZbqxN+pR07kulmZlatQyT9V19t2nQz23ds2bKFESNGMGLECA4//HD69+9f9X7XrsKG3b/22mtZvXp1g3XuvvtuZrdQu++YMWNYunRpiyyrrXWI5p2BA5MmnXzTzaxlzZ6dnEW/+mryP3b77XvXjNq3b9+qBPrNb36Tnj178pWvfKVGnYggIujUKf9x6r333tvo53zhC19ofpAdSIc40r/9dujevea07t2T6WbWcir7z155BSKq+89a48KJtWvXMmzYMG644QZKSkp44403mDJlCqWlpQwdOpRp06ZV1a088q6oqKB3795MnTqVE088kVNPPZWNG5P7RW+77TZmzJhRVX/q1KmMGjWK4447jr/85S8AvPfee3z605/mxBNPZOLEiZSWljZ6RH/fffcxfPhwhg0bxi233AJARUUFn/3sZ6umz5w5E4Dvfve7DBkyhBNPPJHJkye3+DorRIdI+pMmwaxZcNRRICW/Z81yJ65ZS2vr/rOVK1dy3XXXsWTJEvr3788dd9xBWVkZy5Yt48knn2TlypV15tm2bRtjx45l2bJlnHrqqfz4xz/Ou+yIYMGCBUyfPr1qB/L973+fww8/nGXLljF16lSWLFnSYHzl5eXcdtttzJs3jyVLlvDnP/+Zxx57jEWLFrF582aee+45nn/+ea666ioA7rzzTpYuXcqyZcv4wQ9+sJdrp3k6RNKHJMGvXw979iS/nfDNWl5b95997GMf4+STT656/8ADD1BSUkJJSQmrVq3Km/QPPPBAzj//fABOOukk1q9fn3fZl156aZ06zzzzDBMmTADgxBNPZOjQoQ3GN3/+fM4++2wOPfRQunTpwpVXXsnTTz/NMcccw+rVq/nyl7/M3LlzOfjggwEYOnQokydPZvbs2XVurmorHSbpm1nrq6+frLX6z3r06FH1es2aNXzve9/jD3/4A8uXL2fcuHF5r1fv2rVr1euioiIqKiryLvuAAw6oU6epIxTUV79v374sX76cMWPGMHPmTD73uc8BMHfuXG644QYWLFhAaWkpu3fvbtLntQQnfTMrWHv2n73zzjv06tWLgw46iDfeeIO5c+e2+GeMGTOGBx98EIDnnnsu75lErtGjRzNv3jy2bNlCRUUFc+bMYezYsWzatImI4DOf+Qzf+ta3WLx4Mbt376a8vJyzzz6b6dOns2nTJnbUbitrAx3i6h0zaxuVzaYtefVOoUpKShgyZAjDhg3j6KOP5rTTTmvxz/jiF7/IVVddRXFxMSUlJQwbNqyqaSafAQMGMG3aNM4880wigosuuogLL7yQxYsXc9111xERSOLf/u3fqKio4Morr+Tdd99lz549fO1rX6NXr14t/h0a4wHXzDJu1apVnHDCCe0dxj6hoqKCiooKunXrxpo1azjvvPNYs2YNnTvvW8fH+f5mHnDNzKyJtm/fzjnnnENFRQURwT333LPPJfy91bG+jZnZXujduzeLFi1q7zBalTtyzcwyxEnfzCxDnPTNzDLESd/MLEOc9M2sXZ155pl1brSaMWMGn//85xucr2fPngBs2LCByy67rN5lN3YJ+IwZM2rcJHXBBRewdevWQkJv0De/+U3uuuuuvV5OSyso6UsaJ2m1pLWSpuYpv1nSSknLJT0l6aicsoGSfidpVVpnUMuFb2b7u4kTJzJnzpwa0+bMmcPEiRMLmv+jH/0oDz30ULM/v3bSf/zxx+ndu3ezl7evazTpSyoC7gbOB4YAEyUNqVVtCVAaEcXAQ8CdOWU/BaZHxAnAKGBjSwRuZh3DZZddxmOPPcYHH3wAwPr169mwYQNjxoypum6+pKSE4cOH86tf/arO/OvXr2fYsGEA7Ny5kwkTJlBcXMwVV1zBzp07q+rdeOONVcMyf+Mb3wBg5syZbNiwgbPOOouzzjoLgEGDBrF582YAvvOd7zBs2DCGDRtWNSzz+vXrOeGEE/j7v/97hg4dynnnnVfjc/JZunQpo0ePpri4mEsuuYS333676vOHDBlCcXFx1UBvf/zjH6seIjNy5EjefffdZq/bfAq5Tn8UsDYi1gFImgNcDFQNShER83LqPwtMTusOATpHxJNpve0tFLeZtYJ/+Ado6QdCjRgBab7Mq2/fvowaNYrf/va3XHzxxcyZM4crrrgCSXTr1o2HH36Ygw46iM2bNzN69GjGjx9f73Nif/jDH9K9e3eWL1/O8uXLKSkpqSq7/fbbOeSQQ9i9ezfnnHMOy5cv50tf+hLf+c53mDdvHoceemiNZS1atIh7772X+fPnExGccsopjB07lj59+rBmzRoeeOAB/uM//oPLL7+cX/7ylw2Oj3/VVVfx/e9/n7Fjx/L1r3+db33rW8yYMYM77riDl19+mQMOOKCqSemuu+7i7rvv5rTTTmP79u1069atCWu7cYU07/QHXst5X55Oq891wBPp648DWyX9t6QlkqanZw41SJoiqUxS2aZNmwqN3cw6iNwmntymnYjglltuobi4mHPPPZfXX3+dN998s97lPP3001XJt7i4mOLi4qqyBx98kJKSEkaOHMmKFSsaHUztmWee4ZJLLqFHjx707NmTSy+9lD/96U8ADB48mBEjRgAND98Myfj+W7duZezYsQBcffXVPP3001UxTpo0ifvuu6/qzt/TTjuNm2++mZkzZ7J169YWvyO4kKXl26XmHbBH0mSgFBibs/zTgZHAq8DPgWuA/6yxsIhZwCxIxt4pICYzawUNHZG3pk996lPcfPPNLF68mJ07d1Ydoc+ePZtNmzaxaNEiunTpwqBBg/IOp5wr31nAyy+/zF133cXChQvp06cP11xzTaPLaWhcssphmSEZmrmx5p36/OY3v+Hpp5/m0Ucf5dvf/jYrVqxg6tSpXHjhhTz++OOMHj2a3//+9xx//PHNWn4+hRzplwNH5rwfAGyoXUnSucCtwPiI+CBn3iURsS4iKoBHgJLa85pZtvXs2ZMzzzyTv/u7v6vRgbtt2zYOO+wwunTpwrx583gl38Owc5xxxhlVDz9//vnnWb58OZAMy9yjRw8OPvhg3nzzTZ544omqeXr16pW33fyMM87gkUceYceOHbz33ns8/PDDnH766U3+bgcffDB9+vSpOkv42c9+xtixY9mzZw+vvfYaZ511FnfeeSdbt25l+/btvPTSSwwfPpyvfe1rlJaW8sILLzT5MxtSyJH+QuBYSYOB14EJwJW5FSSNBO4BxkXExlrz9pHULyI2AWcDHkLTzOqYOHEil156aY0reSZNmsRFF11EaWkpI0aMaPSI98Ybb+Taa6+luLiYESNGMGrUKCB5CtbIkSMZOnRonWGZp0yZwvnnn88RRxzBvHnV3ZMlJSVcc801Vcu4/vrrGTlyZINNOfX5yU9+wg033MCOHTs4+uijuffee9m9ezeTJ09m27ZtRAT/+I//SO/evfnnf/5n5s2bR1FREUOGDKl6ClhLKWhoZUkXADOAIuDHEXG7pGlAWUQ8Kun3wHDgjXSWVyNifDrv3wD/TtJMtAiYEhG76vssD61s1rY8tPL+p9WHVo6Ix4HHa037es7rcxuY90mguL5yMzNrO74j18wsQ5z0zazJDwS39rO3fysnfbOM69atG1u2bHHi3w9EBFu2bNmrG7b85CyzjBswYADl5eX4xsj9Q7du3RgwYECz53fSN8u4Ll26MHjw4PYOw9qIm3fMzDLESd/MLEOc9M3MMsRJ38wsQ5z0zcwyxEnfzCxDnPTNzDLESd/MLEOc9M3MMsRJ38wsQ5z0zcwyxEnfzCxDnPTNzDLESd/MLEMKSvqSxklaLWmtpKl5ym+WtFLScklPSTqqVvlBkl6X9IOWCtzMzJqu0aQvqQi4GzgfGAJMlDSkVrUlQGlEFAMPAXfWKv828Me9D9fMzPZGIUf6o4C1EbEuInYBc4CLcytExLyI2JG+fRaoeqyLpJOAjwC/a5mQzcysuQpJ+v2B13Lel6fT6nMd8ASApE7AvwNfbegDJE2RVCapzI9sMzNrPYUkfeWZlvcJypImA6XA9HTS54HHI+K1fPWrFhYxKyJKI6K0X79+BYRkZmbNUcgzcsuBI3PeDwA21K4k6VzgVmBsRHyQTj4VOF3S54GeQFdJ2yOiTmewmZm1vkKS/kLgWEmDgdeBCcCVuRUkjQTuAcZFxMbK6RExKafONSSdvU74ZmbtpNHmnYioAG4C5gKrgAcjYoWkaZLGp9WmkxzJ/0LSUkmPtlrEZmbWbIrI2zzfbkpLS6OsrKy9wzAz269IWhQRpY3V8x25ZmYZ4qRvZpYhTvpmZhnipG9mliFO+mZmGeKkb2aWIU76ZmYZ4qRvZpYhTvpmZhnipG9mliFO+mZmGeKkb2aWIU76ZmYZ4qRvZpYhTvpmZhnipG9mliFO+mZmGeKkb2aWIU76ZmYZUlDSlzRO0mpJayVNzVN+s6SVkpZLekrSUen0EZL+V9KKtOyKlv4CZmZWuEaTvqQi4G7gfGAIMFHSkFrVlgClEVEMPATcmU7fAVwVEUOBccAMSb1bKngzM2uaQo70RwFrI2JdROwC5gAX51aIiHkRsSN9+ywwIJ3+YkSsSV9vADYC/VoqeDMza5pCkn5/4LWc9+XptPpcBzxRe6KkUUBX4KU8ZVMklUkq27RpUwEhmZlZcxSS9JVnWuStKE0GSoHptaYfAfwMuDYi9tRZWMSsiCiNiNJ+/XwiYGbWWjoXUKccODLn/QBgQ+1Kks4FbgXGRsQHOdMPAn4D3BYRz+5duGZmtjcKOdJfCBwrabCkrsAE4NHcCpJGAvcA4yNiY870rsDDwE8j4hctF7aZmTVHo0k/IiqAm4C5wCrgwYhYIWmapPFptelAT+AXkpZKqtwpXA6cAVyTTl8qaUTLfw0zMyuEIvI2z7eb0tLSKCsra+8wzMz2K5IWRURpY/V8R66ZWYY46ZuZZYiTvplZhjjpm5lliJO+mVmGOOmbmWWIk76ZWYY46ZuZZYiTvplZhjjpm5lliJO+mVmGOOmbmWWIk76ZWYY46ZuZZYiTvplZhjjpm5lliJO+mVmGOOmbmWWIk76ZWYYUlPQljZO0WtJaSVPzlN8saaWk5ZKeknRUTtnVktakP1e3ZPBmZtY0jSZ9SUXA3cD5wBBgoqQhtaotAUojohh4CLgznfcQ4BvAKcAo4BuS+rRc+GZm1hSFHOmPAtZGxLqI2AXMAS7OrRAR8yJiR/r2WWBA+vqTwJMR8VZEvA08CYxrmdDNzKypCkn6/YHXct6Xp9Pqcx3wRFPmlTRFUpmksk2bNhUQkpmZNUchSV95pkXeitJkoBSY3pR5I2JWRJRGRGm/fv0KCMnMzJqjkKRfDhyZ834AsKF2JUnnArcC4yPig6bMa2ZmbaOQpL8QOFbSYEldgQnAo7kVJI0E7iFJ+BtziuYC50nqk3bgnpdOMzOzdtC5sQoRUSHpJpJkXQT8OCJWSJoGlEXEoyTNOT2BX0gCeDUixkfEW5K+TbLjAJgWEW+1yjcxM7NGKSJv83y7KS0tjbKysvYOw8xsvyJpUUSUNlbPd+SamWWIk76ZWYY46ZuZZYiTvplZhjjpm5lliJO+mVmGOOmbmWWIk76ZWYY46ZuZZYiTvplZhjjpm5lliJO+mVmGOOmbmWWIk76ZWYY46ZuZZYiTvplZhjjpm5lliJO+mVmGOOmbmWVIQUlf0jhJqyWtlTQ1T/kZkhZLqpB0Wa2yOyWtkLRK0kylT043M7O212jSl1QE3A2cDwwBJkoaUqvaq8A1wP215v0EcBpQDAwDTgbG7nXUZmbWLJ0LqDMKWBsR6wAkzQEuBlZWVoiI9WnZnlrzBtAN6AoI6AK8uddRm5lZsxTSvNMfeC3nfXk6rVER8b/APOCN9GduRKxqapBmZtYyCkn6+drgo5CFSzoGOAEYQLKjOFvSGXnqTZFUJqls06ZNhSzazMyaoZCkXw4cmfN+ALChwOVfAjwbEdsjYjvwBDC6dqWImBURpRFR2q9fvwIXbWZmTVVI0l8IHCtpsKSuwATg0QKX/yowVlJnSV1IOnHdvGNm1k4aTfoRUQHcBMwlSdgPRsQKSdMkjQeQdLKkcuAzwD2SVqSzPwS8BDwHLAOWRcSvW+F7mJlZARRRUPN8myktLY2ysrL2DsPMbL8iaVFElDZWz3fkmplliJO+mVmGOOmbmWWIk76ZWYY46ZuZZYiTvplZhjjpm5lliJO+mVmGOOmbmWWIk75ZAWbPhkGDoFOn5Pfs2e0dkVnzFPIQFbNMmz0bpkyBHTuS96+8krwHmDSp/eIyaw4f6Zs14tZbqxN+pR07kulm+xsnfbNGvPpq06ab7cuc9M0aMXBg06ab7cuc9M0acfvt0L17zWnduyfTzfY3TvpmjZg0CWbNgqOOAin5PWuWO3Ft/+Srd8wKMGmSk7x1DD7SNzPLECd9M7MMcdI3M8uQgpK+pHGSVktaK2lqnvIzJC2WVCHpslplAyX9TtIqSSslDWqZ0M3MrKkaTfqSioC7gfOBIcBESUNqVXsVuAa4P88ifgpMj4gTgFHAxr0J2MzMmq+Qq3dGAWsjYh2ApDnAxcDKygoRsT4t25M7Y7pz6BwRT6b1trdM2GZm1hyFNO/0B17LeV+eTivEx4Gtkv5b0hJJ09MzhxokTZFUJqls06ZNBS7azMyaqpCkrzzTosDldwZOB74CnAwcTdIMVHNhEbMiojQiSvv161fgos3MrKkKSfrlwJE57wcAGwpcfjmwJCLWRUQF8AhQ0rQQzcyspRSS9BcCx0oaLKkrMAF4tMDlLwT6SKo8fD+bnL4AMzNrW40m/fQI/SZgLrAKeDAiVkiaJmk8gKSTJZUDnwHukbQinXc3SdPOU5KeI2kq+o/W+SpmrauiAqLQhk2zfZRiH9uKS0tLo6ysrL3DsIzbswfWroX582HBguRn6VI48EAYMQJGjqz+fcIJ0KVLe0dsWSdpUUSUNlbPA66ZAW++mST2yiS/cCFs3ZqU9egBpaXwxS8mT8xasgTuuQd27kzKDzgAhg2ruSM48cRkPrN9jZO+Zc727bBoUfUR/IIF1U/BKiqC4cPh8sth1Cg45ZTkSL6o1oXGu3fDiy8mR/9LliQ/Dz8MP/pRUi7Bxz9ec0cwciT44jRrb27esQ6togKef75mgl+xImm+ARg8OEnulT8lJXUfmFKoCCgvT3YAuTuDV16prtO/f/UOoHJnMGhQspOw7Jo9O3nm8quvJk9ku/32pg/lXWjzjpO+dRgRsH59zQS/aFF1M8whh1Qn91NOgZNPbpsj77feSnYCuTuCVauqdzy9e+fvJ+js8/BMmD0bpkxJmg4rde/e9Af1OOlbh7dlS9L2npvkK2/oPuCA5Ki9MsGPGgVHH73vHFHv3AnPPVfzrGD58pr9BMOH19wRFBe7n6AjGjSo5tlgpaOOSg5iCuWkbx3Kzp1JcsxN8GvXJmVScmScm+CHD9//rqipqEj6CWo3D731VlLeqVN1P0HuzuDQQ9s3bts7nTrlvxRYqj4bLISTvu239uyBF16omeCXLUuSIiTt4pXJfdQoOOkkOOig9o25tUTAa6/V3RFUdjwDDBhQd0dQ+Txf2/e19ZG+Ww2t3b3+es0Ev3AhvPtuUnbQQUnb+1e/miT4k09Okn5WSEnH3sCBcPHF1dO3bKneCVT+/s1vqo8M+/Sp209w/PHuJ9gX3X57/jb9229vnc/zkb61qXfegbKy6gQ/fz5sSEdy6tw5ub499yj+uOOS019r3I4d+fsJ3n8/Ke/WrbqfoHJnUFzc/KuVrOX46h0n/Q5h164kCeUm+BdeqG6/POaYmgl+xIgkMVnLqaiA1avrNg+9/XZS3qlTsmOt3TzUt2/7xm1N56RvbSoCXnqpZoJfsgQ++CAp79evZoI/+eTkEkprexHJEWXtHcFrOU/NOPLIujuCgQPdT7Avc9K3VrVpU80Ev3Bh9VUm3bsnnau5Nz25Y3Hft3lz3X6C1aur+wkOOaRuP8Fxx7mfYF/hpG8tZscOWLy45tg0lVdUX8PwAAAKsklEQVQVdOqUjDuTm+CHDnUi6Ch27Ej6BWr3E1SewXXrlvQL5J4VDB/ufoL24KRvzbJ7N6xcWTPBP/98Mh2SI/bcBH/SSb5hKGsqKpK+mcpmocqdQeUAdZ06JVcK1W4ecnNe63LSt0ZVXgOem+AXLYL33kvKe/euO2zBRz7SvjHbvikiuda89o6gvLy6zsCBdXcERx7pZr+W4qRvdbz9dnK5ZO4Y8W++mZR17Zr8E+Ym+WOO8T+k7Z1Nm/L3E1Smnb59a45COmJE0k9Qe1RTa5yTfsZ98EFyF2tugn/xxery44+vOWxBcXGS+M1a23vv1e0neO656n6CAw/M309w4IHtG/e+zkk/Q/bsgTVr6j7l6cMPk/LDD0+Se2WCLy2Fgw9u35jNcn34YXU/Qe5lpNu2JeVFRfn7Cfr0ad+49yVO+h3YX/9aM8EvXFj9z9GzZ5LUc6+J79/fzTS2/6kcKrt2P8Hrr1fXOeqoujuCAQOyub23aNKXNA74HlAE/Cgi7qhVfgYwAygGJkTEQ7XKDyJ5qPrDEXFTQ5/lpF/T9u01hy1YsKD6JprOnZPT4NyraY4/3u2h1rFt3Fi3n+DFF2v2E9TeEXz84x3//6LFBlyTVATcDfwNUA4slPRoRKzMqfYqcA3wlXoW823gj419VtZ9+GHdpzytXFl9c8zHPgZjxlQn+JEj3c5p2XPYYXDeeclPpe3bq/sJKncG3/teMhQIJPcN5OsnyOKwH4XcQjMKWBsR6wAkzQEuBqqSfkSsT8vqjP4s6STgI8BvgUb3QlkRAS+/XDPBL15c/RCNvn2TJprLLqsetsDjppvl17MnfOITyU+lDz9MnlCWuyO4/3744Q+T8qKi5DkMuTuCESM6fj9BIUm/P5AzKgflwCmFLFxSJ+Dfgc8C5zRQbwowBWDgwIGFLHq/s3lz3ac8bd6clHXrltzkdMMN1Ufxgwdns13SrKV06ZIc3RcXw9VXJ9MqD7ZydwRPPQU/+1n1fIMG1W0e6kj9YoUk/XxftdDe388Dj0fEa2pgjUXELGAWJG36BS57n7VzZ7JB5Sb4l15KyqRkmILx46sT/LBh+99Tnsz2R1Ly2Myjj4ZPf7p6+saN1TuCyp3BI49U9xMcemj1jqByZ3DssftnP0EhSb8cODLn/QBgQ4HLPxU4XdLngZ5AV0nbI2Jq08Lcd+3eXfcpT8uXVz/l6cgjk8Q+ZUr1sAW9erVvzGZW02GHwSc/mfxUevfduv0EM2ZU9xP06FG3n2DYsH2/n6DRq3ckdQZeJGmeeR1YCFwZESvy1P0v4LHaV++kZdcApfvz1TsRNZ/yNH9+cmXN9u1J+cEHJ23vucMWHHFE+8ZsZi1n166a/QSVO4PKJ7117py/n6B379aPraUv2byA5JLMIuDHEXG7pGlAWUQ8Kulk4GGgD/A+8NeIGFprGdewnyX9bduqL5esvC7+jTeSsi5dkj9m7l2txx7rpzyZZc2ePTX7CSp3BJW5ApI+utr9BB/9aMv2E/jmrCbatSs5lav9lKdKH/94zQR/4olwwAFtHqaZ7SfefLPujmDNmuryfv3y9xM098DRSb8BEbB2bd2nPFW21R12WN1hCzr6ZVxm1vrefTcZEyt3Z7BiRfWQKSUlyUi3zdFiN2d1BBs31n3KU+UzQrt3T5L6l79cfTWNh3s1s9bQq1dyg+WYMdXTdu1KbsJcsqRtmoc7XNJ/7726T3l65ZWkrKgo6V3/zGeqE/wJJ/gpT2bWfrp2re7wbQsdJt2Vl8OFFybDGFQOWzBoEIweDV/6UvWwBX7Kk5llWYdJ+h/5SPJknk99qnrYgsMOa++ozMz2LR0m6XfpAr/+dXtHYWa2b/NV5WZmGeKkb2aWIU76ZmYZ4qRvZpYhTvpmZhnipG9mliFO+mZmGeKkb2aWIfvcKJuSNgGv7MUiDgU2t1A4LclxNY3jahrH1TQdMa6jIqJfY5X2uaS/tySVFTK8aFtzXE3juJrGcTVNluNy846ZWYY46ZuZZUhHTPqz2juAejiupnFcTeO4miazcXW4Nn0zM6tfRzzSNzOzejjpm5llyH6T9CX9WNJGSc/XUy5JMyWtlbRcUklO2dWS1qQ/V7dxXJPSeJZL+oukE3PK1kt6TtJSSWVtHNeZkraln71U0tdzysZJWp2uy6ltHNdXc2J6XtJuSYekZa25vo6UNE/SKkkrJH05T5023cYKjKm9tq9CYmvzbazAuNp8G5PUTdICScvSuL6Vp84Bkn6erpP5kgbllP2fdPpqSZ/cq2AiYr/4Ac4ASoDn6ym/AHgCEDAamJ9OPwRYl/7uk77u04ZxfaLy84DzK+NK368HDm2n9XUm8Fie6UXAS8DRQFdgGTCkreKqVfci4A9ttL6OAErS172AF2t/77bexgqMqb22r0Jia/NtrJC42mMbS7eZnunrLsB8YHStOp8H/l/6egLw8/T1kHQdHQAMTtddUXNj2W+O9CPiaeCtBqpcDPw0Es8CvSUdAXwSeDIi3oqIt4EngXFtFVdE/CX9XIBngQEt9dl7E1cDRgFrI2JdROwC5pCs2/aIayLwQEt9dkMi4o2IWJy+fhdYBfSvVa1Nt7FCYmrH7auQ9VWfVtvGmhFXm2xj6TazPX3bJf2pfRXNxcBP0tcPAedIUjp9TkR8EBEvA2tJ1mGz7DdJvwD9gddy3pen0+qb3h6uIzlSrBTA7yQtkjSlHeI5NT3dfELS0HTaPrG+JHUnSZy/zJncJusrPa0eSXI0lqvdtrEGYsrVLttXI7G12zbW2Dpr621MUpGkpcBGkoOEereviKgAtgF9aeH11WEejE5y+lRbNDC9TUk6i+SfckzO5NMiYoOkw4AnJb2QHgm3hcUkY3Vsl3QB8AhwLPvI+iI57f5zROSeFbT6+pLUkyQJ/ENEvFO7OM8srb6NNRJTZZ122b4aia3dtrFC1hltvI1FxG5ghKTewMOShkVEbt9Wm2xfHelIvxw4Muf9AGBDA9PbjKRi4EfAxRGxpXJ6RGxIf28EHmYvTtmaKiLeqTzdjIjHgS6SDmUfWF+pCdQ67W7t9SWpC0mimB0R/52nSptvYwXE1G7bV2Oxtdc2Vsg6S7X5NpYueyvwP9RtAqxaL5I6AweTNIW27Ppq6Q6L1vwBBlF/x+SF1OxkW5BOPwR4maSDrU/6+pA2jGsgSRvcJ2pN7wH0ynn9F2BcG8Z1ONU3540CXk3XXWeSjsjBVHeyDW2ruNLyyo29R1utr/S7/xSY0UCdNt3GCoypXbavAmNr822skLjaYxsD+gG909cHAn8C/rZWnS9QsyP3wfT1UGp25K5jLzpy95vmHUkPkFwNcKikcuAbJJ0hRMT/Ax4nubpiLbADuDYte0vSt4GF6aKmRc3TudaO6+sk7XL/N+mToSKSUfQ+QnKKB8k/wf0R8ds2jOsy4EZJFcBOYEIkW1iFpJuAuSRXWfw4Ila0YVwAlwC/i4j3cmZt1fUFnAZ8FngubXcFuIUkqbbXNlZITO2yfRUYW3tsY4XEBW2/jR0B/ERSEUkLy4MR8ZikaUBZRDwK/CfwM0lrSXZIE9KYV0h6EFgJVABfiKSpqFk8DIOZWYZ0pDZ9MzNrhJO+mVmGOOmbmWWIk76ZWYY46ZuZZYiTvplZhjjpm5llyP8HZBPCjyI5O50AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  delta(min)    #train    #test    train loss(last)    train_f1(last)    val loss     val f1\n",
      "------------  --------  -------  ------------------  ----------------  -----------  --------\n",
      "          15      2134      533            0.152141          0.931024     0.135208  0.967304\n",
      "results: [[15, 2134, 533, 0.15214142214503373, 0.9310238169193714, 0.13520763421514836, 0.9673041832156297]]\n",
      "number_of_lstm_layers: 3\n",
      "delta: 15\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2134, 20)\n",
      "x_test shape: (533, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 2134 samples, validate on 533 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-df3711a61860>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m results = select_hyperparameters(address_to_read = address_to_read , \n\u001b[0;32m      8\u001b[0m                                  \u001b[0mID_of_layer_to_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mID_of_layer_to_repeat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                                  hasActivitycol = hasActivitycol)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-de21398249fa>\u001b[0m in \u001b[0;36mselect_hyperparameters\u001b[1;34m(address_to_read, ID_of_layer_to_repeat, hasActivitycol)\u001b[0m\n\u001b[0;32m     20\u001b[0m                                                                                                 \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                                                                                                 \u001b[0mnumber_of_lstm_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                                                                                                 ID_of_layer_to_repeat = ID_of_layer_to_repeat )\n\u001b[0m\u001b[0;32m     23\u001b[0m             results.append([delta, \n\u001b[0;32m     24\u001b[0m                         \u001b[0mnum_of_train_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-6432e95bd8fd>\u001b[0m in \u001b[0;36mcreate_model_and_apply_on_data\u001b[1;34m(x_train, y_train, x_test, y_test, max_features, embedding_vector_dim, batch_size, epochs, loss, optimizer, metrics, plot_trainvalgraph, number_of_lstm_layers, ID_of_layer_to_repeat)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             validation_data=(x_test, y_test))\n\u001b[0m\u001b[0;32m     47\u001b[0m   score, acc = model.evaluate(x_test, y_test,\n\u001b[0;32m     48\u001b[0m                               batch_size=batch_size)\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2697\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2698\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2699\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 199\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#address_to_read, hasActivitycol= r\"E:/pgmpy\\Twor2009\\Seq of sensor events_based on activities\\based_on_activities.csv\", True\n",
    "address_to_read, hasActivitycol = r\"E:\\pgmpy\\Twor2009\\Seq of sensor events_no overlap_based on different deltas\\delta_{}min.csv\", False\n",
    "#address_to_read, hasActivitycol = r\"E:\\pgmpy\\Twor2009\\Seq of sensor events_based_on_activity_and_no_overlap_delta\\delta_{}min.csv\", True\n",
    "print(address_to_read)\n",
    "ID_of_layer_to_repeat = 0\n",
    "print(\"ID_of_layer_to_repeat:\" , ID_of_layer_to_repeat)\n",
    "results = select_hyperparameters(address_to_read = address_to_read , \n",
    "                                 ID_of_layer_to_repeat = ID_of_layer_to_repeat, \n",
    "                                 hasActivitycol = hasActivitycol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d20da67344a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(results[:][-1])\n",
    "print(np.argmax(results[:][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (3, 20)\n",
      "x_test shape: (0, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 40,961\n",
      "Trainable params: 40,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e900f81b9e88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                                                                                         \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                                                                                                         \u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                                                                                                         ID_of_layer_to_repeat = ID_of_layer_to_repeat)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_score:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_acc:\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-b17a894e2105>\u001b[0m in \u001b[0;36mcreate_model_and_apply_on_data\u001b[1;34m(x_train, y_train, x_test, y_test, max_features, embedding_vector_dim, batch_size, epochs, loss, optimizer, metrics, plot_train_val_graph, number_of_lstm_layers, ID_of_layer_to_repeat)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             validation_data=(x_test, y_test))\n\u001b[0m\u001b[0;32m     47\u001b[0m   score, acc = model.evaluate(x_test, y_test,\n\u001b[0;32m     48\u001b[0m                               batch_size=batch_size)\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m                 \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m                 batch_size=batch_size)\n\u001b[0m\u001b[0;32m    973\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mval_ins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     78\u001b[0m                              'for each key in: ' + str(names))\n\u001b[0;32m     79\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "address_to_read= r\"E:/pgmpy/Test2/Seq of sensor events_based on activities/based_on_activities.csv\"\n",
    "\n",
    "x_train, x_test, y_train, y_test, max_features, maxlen = data_preparation_for_sequences_based_deep_models(address_to_read,\n",
    "                                                                                                         number_of_words = 122, \n",
    "                                                                                                        max_seq_len = 20,\n",
    "                                                                                                         hasActivitycol = True)\n",
    "ID_of_layer_to_repeat = 0\n",
    "test_score, test_acc, history, num_of_train_samples, num_of_test_sample = create_model_and_apply_on_data(x_train, \n",
    "                                                                                                        y_train,\n",
    "                                                                                                        x_test, \n",
    "                                                                                                        y_test, \n",
    "                                                                                                        max_features,\n",
    "                                                                                                        ID_of_layer_to_repeat = ID_of_layer_to_repeat)\n",
    "print(\"test_score:\",test_score)\n",
    "print(\"test_acc:\" , test_acc)\n",
    "print(\"history:\" , history.history)\n",
    "print(\"num_of_train_samples:\" , num_of_train_samples)\n",
    "print(\"num_of_test_sample:\" , num_of_test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "bUbyz1O5TtEV",
    "outputId": "fe5bdddd-33a3-4b28-94f0-d6de4758ee37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 10)\n",
      "x_test shape: (25000, 10)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 10)          200010    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                19200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 219,275\n",
      "Trainable params: 219,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 16s 653us/step - loss: 0.6015 - acc: 0.6613 - val_loss: 0.5451 - val_acc: 0.7164\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 0.5163 - acc: 0.7428 - val_loss: 0.5393 - val_acc: 0.7214\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 13s 539us/step - loss: 0.4896 - acc: 0.7652 - val_loss: 0.5306 - val_acc: 0.7294\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 14s 568us/step - loss: 0.4741 - acc: 0.7750 - val_loss: 0.5297 - val_acc: 0.7327\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 14s 557us/step - loss: 0.4628 - acc: 0.7802 - val_loss: 0.5289 - val_acc: 0.7295\n",
      "25000/25000 [==============================] - 2s 65us/step\n",
      "Test score: 0.528882891769\n",
      "Test accuracy: 0.72952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.52888289176940917,\n",
       " 0.72951999999999995,\n",
       " <keras.callbacks.History at 0x261d2fd8908>,\n",
       " 25000,\n",
       " 25000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, max_features, maxlen = imdb_lstm_data_preparation(maxlen=10)\n",
    "#my_x_train, my_x_test, my_y_train, my_y_test, my_max_features, my_maxlen = data_preparation_for_sequences_based_deep_models(address_to_read)\n",
    "#x_train, x_test, y_train, y_test, max_features, maxlen = data_preparation_for_sequences_based_deep_models(address_to_read)#imdb_lstm_data_preparation(maxlen=10)\n",
    "create_model_and_apply_on_data(x_train, y_train,x_test, y_test, max_features,embedding_vector_dim = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rhnw6Y4kQbIz"
   },
   "outputs": [],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPT1K2r9RsFo"
   },
   "outputs": [],
   "source": [
    "# `word_to_index` is a mapping (i.e. dict) from words to their index, e.g. `love`: 69\n",
    "words_embeddings = {w:embeddings[idx] for w, idx in word_to_index.items()}\n",
    "\n",
    "# now you can use it like this for example\n",
    "print(words_embeddings['love'])  # possible output: [0.21, 0.56, ..., 0.65, 0.10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhQ1x75KbI19"
   },
   "outputs": [],
   "source": [
    "print(type(score) , type(acc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "imdb_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
