{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aslesani/pgmpy_fork/blob/master/src/default_test/imdb_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OmJrgoGBTfgJ",
    "outputId": "39d708de-ab42-4288-bee6-7bcc5970b9b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "# Notes\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "from read_write import data_preparation_for_sequences_based_deep_models, convert_binary_classes_to_zero_and_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJSdFzlqcakL"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_val_graph(history):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  epochs = range(1, len(loss) + 1)\n",
    "  print('epochs:' , epochs)\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChXfRjq4jJko"
   },
   "outputs": [],
   "source": [
    "def get_max_len_of_sequences(list_of_sequences):\n",
    "  lengths = [len(list_of_sequences[i]) for i in range(len(list_of_sequences))]\n",
    "  return max(lengths) , min(lengths) , lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_zUyBhXljmq"
   },
   "outputs": [],
   "source": [
    "def get_set_of_sensor_events(list_of_sequences):\n",
    " \n",
    "  set_of_sensor_events = set()\n",
    "  \n",
    "  for i in range(len(list_of_sequences)):\n",
    "      set_of_sensor_events = set_of_sensor_events.union(set(list_of_sequences[i]))\n",
    "  \n",
    "  return set_of_sensor_events, len(set_of_sensor_events)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "PSnIdgbbWlm6",
    "outputId": "fafa8eb3-bf07-40db-c168-948bf988ded0"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/aslesani/pgmpy_fork.git\n",
    "#ls\n",
    "#!git clone https://github.com/aslesani/created_dataset.git\n",
    "#!rm -r pgmpy_fork  \n",
    "#cd pgmpy_fork/src/default_test\n",
    "#cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Adhup5wx35Il"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def mcor(y_true, y_pred):\n",
    "    #matthews_correlation\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    " \n",
    " \n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    " \n",
    " \n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    " \n",
    " \n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    " \n",
    " \n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    " \n",
    " \n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w0em365aEiF1",
    "outputId": "c94c0dd6-1e9f-484d-e710-5a7a07f62720"
   },
   "outputs": [],
   "source": [
    "#!pip install tabulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "wRPxCWPzExrc",
    "outputId": "a2e3e2fd-0584-40cc-ac2e-ca74216c0867"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "#print(tabulate([['Alice', 24], ['Bob', 19]], headers=['algorithm', 'acc']))\n",
    "\n",
    "def print_list_of_lists(data , headers):\n",
    "    print(tabulate(data, headers=headers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_print_list_of_lists():\n",
    "    data = [['Alice', 24], ['Bob', 19]]\n",
    "    headers=['algorithm', 'acc']\n",
    "    print_list_of_lists(data , headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm      acc\n",
      "-----------  -----\n",
      "Alice           24\n",
      "Bob             19\n"
     ]
    }
   ],
   "source": [
    "test_print_list_of_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cM2IkLSSM458"
   },
   "outputs": [],
   "source": [
    "def imdb_lstm_data_preparation(max_features = 20000, maxlen = 80):\n",
    "  #max_features = 20000#number_of_events\n",
    "  # cut texts after this number of words (among top max_features most common words)\n",
    "  #maxlen = 10#max_seq_len\n",
    "\n",
    "  print('Loading data...')\n",
    "  (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "  print(len(x_train), 'train sequences')\n",
    "  print(len(x_test), 'test sequences')\n",
    "\n",
    "  #print('before apply pad_sequence, x_train[0]:' , x_train[0])\n",
    "\n",
    "  print('Pad sequences (samples x time)')\n",
    "  x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "  x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "  print('x_train shape:', x_train.shape)\n",
    "  print('x_test shape:', x_test.shape)\n",
    "  \n",
    "  return x_train, x_test, y_train, y_test, max_features, maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Npd2VghtklVO"
   },
   "outputs": [],
   "source": [
    "#! cd pgmpy_fork/src/default_test\n",
    "#!ls\n",
    "#!git clone https://github.com/pgmpy/pgmpy \n",
    "#cd ..\n",
    "#!ls\n",
    "#!cd pgmpy/\n",
    "#pip install -r requirements.txt\n",
    "#!python setup.py install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lstm_without_embedding(x_train, y_train,x_test, y_test, max_features,embedding_vector_dim = 64, batch_size = 32, epochs = 5, \n",
    "                                   loss = 'binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'], plot_train_val_graph = False):\n",
    "  \n",
    "  #batch_size = 32\n",
    "\n",
    "  print('Build model...')\n",
    "  model = Sequential()\n",
    "  #model.add(Embedding(max_features+1, embedding_vector_dim))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  # try using different optimizers and different optimizer configs\n",
    "  model.compile(loss= loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics= metrics)#, mcor,recall, f1])\n",
    "\n",
    "  print('Train...')\n",
    "  history = model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test))\n",
    "  score, acc = model.evaluate(x_test, y_test,\n",
    "                              batch_size=batch_size)\n",
    "  print('Test score:', score)# i think score is loss value\n",
    "  print('Test accuracy:', acc)\n",
    " \n",
    "  if plot_train_val_graph:\n",
    "      plot_train_val_graph(history)\n",
    "      \n",
    "  return score, acc, history, len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsUaDYDeTx3t"
   },
   "outputs": [],
   "source": [
    "def create_model_and_apply_on_data(x_train, y_train,x_test, y_test, max_features,\n",
    "                                   embedding_vector_dim = 64, batch_size = 32, epochs = 10, \n",
    "                                   loss = 'binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'], \n",
    "                                   plot_train_val_graph = False,\n",
    "                                   number_of_lstm_layers = 1,\n",
    "                                   ID_of_layer_to_repeat = 0):\n",
    "  '''\n",
    "  Parameters:\n",
    "  ===============\n",
    "  number_of_lstm_layers (default value = 1)\n",
    "      indicate the number of layers in stack of layers\n",
    "  \n",
    "  ID_of_layer_to_repeat (default value = 0)\n",
    "     0: LSTM\n",
    "     1:RNN\n",
    "     2: GRU\n",
    "  \n",
    "  '''\n",
    "  #batch_size = 32\n",
    "\n",
    "  print('Build model...')\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(max_features+1, embedding_vector_dim))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  \n",
    "  layer_names = [LSTM, SimpleRNN, GRU]\n",
    "  if number_of_lstm_layers > 1:\n",
    "        for l in range(number_of_lstm_layers-1):\n",
    "            model.add(layer_names[ID_of_layer_to_repeat](64, dropout=0.2, recurrent_dropout=0.2, return_sequences = True))\n",
    "  model.add(layer_names[ID_of_layer_to_repeat](64, dropout=0.2, recurrent_dropout=0.2))\n",
    "        \n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  # try using different optimizers and different optimizer configs\n",
    "  model.compile(loss= loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics= metrics)#, mcor,recall, f1])\n",
    "\n",
    "  print('Train...')\n",
    "  history = model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test))\n",
    "  score, acc = model.evaluate(x_test, y_test,\n",
    "                              batch_size=batch_size)\n",
    "  #print('Test score:', score)# i think score is loss value\n",
    "  #print('Test accuracy:', acc)\n",
    " \n",
    "  #print(model.layers[0].output)\n",
    "  if plot_train_val_graph:\n",
    "      plot_train_val_graph(history)\n",
    "      \n",
    "  return score, acc, history, len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMsynyAJJCnJ"
   },
   "outputs": [],
   "source": [
    "def select_hyperparameters(address_to_read, ID_of_layer_to_repeat):\n",
    "    #address_to_read= r\"E:/pgmpy/Seq of sensor events_based on activities/based_on_activities.csv\"\n",
    "    #address_to_read = r\"E:\\pgmpy\\Seq of sensor events_no overlap_based on different deltas\\delta_{}min.csv\"\n",
    "    #address_to_read = r\"E:\\pgmpy\\Seq of sensor events_based_on_activity_and_no_overlap_delta\\delta_{}min.csv\"\n",
    "    \n",
    "    for layers in range(2,5):\n",
    "        print(\"number_of_lstm_layers:\" , layers)\n",
    "\n",
    "        results = []\n",
    "        for delta in list(range(1,10)):# + [30,45,60,75,90,100]:#, 120,150, 180,200,240,300,400,500,600,700,800,900,1000]: #:\n",
    "            print(\"delta:\" , delta)\n",
    "            x_train, x_test, y_train, y_test, max_features, maxlen = data_preparation_for_sequences_based_deep_models(address_to_read = address_to_read.format(delta),\n",
    "                                                                                                                  number_of_words = 122, \n",
    "                                                                                                                  max_seq_len = 20)\n",
    "            test_score, test_acc, history, num_of_train_samples, num_of_test_sample = create_model_and_apply_on_data(x_train =x_train, \n",
    "                                                                                                y_train = y_train,\n",
    "                                                                                                x_test = x_test, \n",
    "                                                                                                y_test = y_test, \n",
    "                                                                                                max_features = max_features,\n",
    "                                                                                                number_of_lstm_layers = layers,\n",
    "                                                                                                ID_of_layer_to_repeat = ID_of_layer_to_repeat )\n",
    "            results.append([delta, \n",
    "                        num_of_train_samples, \n",
    "                        num_of_test_sample, \n",
    "                        history.history['loss'][-1], \n",
    "                        history.history['acc'][-1] ,\n",
    "                        test_score, \n",
    "                        test_acc])#, history.history\n",
    "        #print(history.history)\n",
    "        print_list_of_lists(results, ['delta(min)' ,\n",
    "                                  '#train', \n",
    "                                  '#test', \n",
    "                                  'train loss(last)', \n",
    "                                  'train_acc(last)', \n",
    "                                  'val loss ', \n",
    "                                  'val acc', ])#'history'\n",
    "        print(\"results:\", results)\n",
    "        #print(\"results[:][-1]:\", results[:][-1])\n",
    "        #best_val_acc_index = np.argmax(results[:][-1])\n",
    "        #print(\"****************************************\")\n",
    "        #print(\"best vlidation acc delta:\" , results[best_val_acc_index][0])\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\pgmpy\\Twor2009\\Seq of sensor events_no overlap_based on different deltas\\delta_{}min.csv\n",
      "ID_of_layer_to_repeat: 0\n",
      "number_of_lstm_layers: 2\n",
      "delta: 1\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (11618, 20)\n",
      "x_test shape: (2904, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_90 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_91 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 11618 samples, validate on 2904 samples\n",
      "Epoch 1/10\n",
      "11618/11618 [==============================] - 191s 16ms/step - loss: 0.2163 - acc: 0.9108 - val_loss: 0.2151 - val_acc: 0.8977\n",
      "Epoch 2/10\n",
      "11618/11618 [==============================] - 28s 2ms/step - loss: 0.1597 - acc: 0.9347 - val_loss: 0.2164 - val_acc: 0.9012\n",
      "Epoch 3/10\n",
      "11618/11618 [==============================] - 30s 3ms/step - loss: 0.1543 - acc: 0.9377 - val_loss: 0.1395 - val_acc: 0.9387\n",
      "Epoch 4/10\n",
      "11618/11618 [==============================] - 31s 3ms/step - loss: 0.1529 - acc: 0.9383 - val_loss: 0.2035 - val_acc: 0.9194\n",
      "Epoch 5/10\n",
      "11618/11618 [==============================] - 31s 3ms/step - loss: 0.1510 - acc: 0.9393 - val_loss: 0.1769 - val_acc: 0.9366\n",
      "Epoch 6/10\n",
      "11618/11618 [==============================] - 31s 3ms/step - loss: 0.1511 - acc: 0.9393 - val_loss: 0.2533 - val_acc: 0.8981\n",
      "Epoch 7/10\n",
      "11618/11618 [==============================] - 31s 3ms/step - loss: 0.1480 - acc: 0.9388 - val_loss: 0.2022 - val_acc: 0.9156\n",
      "Epoch 8/10\n",
      "11618/11618 [==============================] - 31s 3ms/step - loss: 0.1494 - acc: 0.9409 - val_loss: 0.2144 - val_acc: 0.9108\n",
      "Epoch 9/10\n",
      "11618/11618 [==============================] - 31s 3ms/step - loss: 0.1474 - acc: 0.9417 - val_loss: 0.2312 - val_acc: 0.9098\n",
      "Epoch 10/10\n",
      "11618/11618 [==============================] - 31s 3ms/step - loss: 0.1473 - acc: 0.9402 - val_loss: 0.1757 - val_acc: 0.9253\n",
      "2904/2904 [==============================] - 2s 636us/step\n",
      "delta: 2\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (7737, 20)\n",
      "x_test shape: (1934, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_92 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_93 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 7737 samples, validate on 1934 samples\n",
      "Epoch 1/10\n",
      "7737/7737 [==============================] - 64s 8ms/step - loss: 0.2162 - acc: 0.9174 - val_loss: 0.1341 - val_acc: 0.9674\n",
      "Epoch 2/10\n",
      "7737/7737 [==============================] - 22s 3ms/step - loss: 0.1485 - acc: 0.9422 - val_loss: 0.1749 - val_acc: 0.9276\n",
      "Epoch 3/10\n",
      "7737/7737 [==============================] - 22s 3ms/step - loss: 0.1428 - acc: 0.9461 - val_loss: 0.2110 - val_acc: 0.9054\n",
      "Epoch 4/10\n",
      "7737/7737 [==============================] - 21s 3ms/step - loss: 0.1401 - acc: 0.9462 - val_loss: 0.1534 - val_acc: 0.9297\n",
      "Epoch 5/10\n",
      "7737/7737 [==============================] - 21s 3ms/step - loss: 0.1396 - acc: 0.9467 - val_loss: 0.2069 - val_acc: 0.9271\n",
      "Epoch 6/10\n",
      "7737/7737 [==============================] - 21s 3ms/step - loss: 0.1371 - acc: 0.9479 - val_loss: 0.1557 - val_acc: 0.9349\n",
      "Epoch 7/10\n",
      "7737/7737 [==============================] - 21s 3ms/step - loss: 0.1358 - acc: 0.9482 - val_loss: 0.1780 - val_acc: 0.9359\n",
      "Epoch 8/10\n",
      "7737/7737 [==============================] - 21s 3ms/step - loss: 0.1347 - acc: 0.9484 - val_loss: 0.1914 - val_acc: 0.9276\n",
      "Epoch 9/10\n",
      "7737/7737 [==============================] - 25s 3ms/step - loss: 0.1353 - acc: 0.9487 - val_loss: 0.1760 - val_acc: 0.9328\n",
      "Epoch 10/10\n",
      "7737/7737 [==============================] - 23s 3ms/step - loss: 0.1328 - acc: 0.9500 - val_loss: 0.1694 - val_acc: 0.9224\n",
      "1934/1934 [==============================] - 1s 731us/step\n",
      "delta: 3\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (6047, 20)\n",
      "x_test shape: (1511, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_94 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_95 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 6047 samples, validate on 1511 samples\n",
      "Epoch 1/10\n",
      "6047/6047 [==============================] - 56s 9ms/step - loss: 0.2265 - acc: 0.9133 - val_loss: 0.2372 - val_acc: 0.8901\n",
      "Epoch 2/10\n",
      "6047/6047 [==============================] - 16s 3ms/step - loss: 0.1502 - acc: 0.9408 - val_loss: 0.1559 - val_acc: 0.9246\n",
      "Epoch 3/10\n",
      "6047/6047 [==============================] - 16s 3ms/step - loss: 0.1419 - acc: 0.9433 - val_loss: 0.1816 - val_acc: 0.9259\n",
      "Epoch 4/10\n",
      "6047/6047 [==============================] - 17s 3ms/step - loss: 0.1391 - acc: 0.9461 - val_loss: 0.1464 - val_acc: 0.9550\n",
      "Epoch 5/10\n",
      "6047/6047 [==============================] - 16s 3ms/step - loss: 0.1371 - acc: 0.9464 - val_loss: 0.1652 - val_acc: 0.9345\n",
      "Epoch 6/10\n",
      "6047/6047 [==============================] - 16s 3ms/step - loss: 0.1360 - acc: 0.9469 - val_loss: 0.1698 - val_acc: 0.9272\n",
      "Epoch 7/10\n",
      "6047/6047 [==============================] - 19s 3ms/step - loss: 0.1370 - acc: 0.9466 - val_loss: 0.1769 - val_acc: 0.9378\n",
      "Epoch 8/10\n",
      "6047/6047 [==============================] - 18s 3ms/step - loss: 0.1355 - acc: 0.9482 - val_loss: 0.1774 - val_acc: 0.9471\n",
      "Epoch 9/10\n",
      "6047/6047 [==============================] - 18s 3ms/step - loss: 0.1325 - acc: 0.9487 - val_loss: 0.1806 - val_acc: 0.9537\n",
      "Epoch 10/10\n",
      "6047/6047 [==============================] - 17s 3ms/step - loss: 0.1328 - acc: 0.9484 - val_loss: 0.1853 - val_acc: 0.9444: 0.1285  -\n",
      "1511/1511 [==============================] - 1s 689us/step\n",
      "delta: 4\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (5078, 20)\n",
      "x_test shape: (1269, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_36 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_96 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_97 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 5078 samples, validate on 1269 samples\n",
      "Epoch 1/10\n",
      "5078/5078 [==============================] - 82s 16ms/step - loss: 0.2358 - acc: 0.9080 - val_loss: 0.1625 - val_acc: 0.9409\n",
      "Epoch 2/10\n",
      "5078/5078 [==============================] - 13s 3ms/step - loss: 0.1494 - acc: 0.9427 - val_loss: 0.1429 - val_acc: 0.9645\n",
      "Epoch 3/10\n",
      "5078/5078 [==============================] - 14s 3ms/step - loss: 0.1397 - acc: 0.9447 - val_loss: 0.1826 - val_acc: 0.9346\n",
      "Epoch 4/10\n",
      "5078/5078 [==============================] - 14s 3ms/step - loss: 0.1350 - acc: 0.9462 - val_loss: 0.1626 - val_acc: 0.9441\n",
      "Epoch 5/10\n",
      "5078/5078 [==============================] - 14s 3ms/step - loss: 0.1333 - acc: 0.9484 - val_loss: 0.1546 - val_acc: 0.9401\n",
      "Epoch 6/10\n",
      "5078/5078 [==============================] - 14s 3ms/step - loss: 0.1323 - acc: 0.9478 - val_loss: 0.1594 - val_acc: 0.9496\n",
      "Epoch 7/10\n",
      "5078/5078 [==============================] - 14s 3ms/step - loss: 0.1302 - acc: 0.9502 - val_loss: 0.1626 - val_acc: 0.9377\n",
      "Epoch 8/10\n",
      "5078/5078 [==============================] - 14s 3ms/step - loss: 0.1320 - acc: 0.9506 - val_loss: 0.1884 - val_acc: 0.9259\n",
      "Epoch 9/10\n",
      "5078/5078 [==============================] - 14s 3ms/step - loss: 0.1315 - acc: 0.9502 - val_loss: 0.1323 - val_acc: 0.9480\n",
      "Epoch 10/10\n",
      "5078/5078 [==============================] - 14s 3ms/step - loss: 0.1288 - acc: 0.9506 - val_loss: 0.1580 - val_acc: 0.9480\n",
      "1269/1269 [==============================] - 1s 675us/step\n",
      "delta: 5\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (4432, 20)\n",
      "x_test shape: (1107, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_37 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_98 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_99 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 4432 samples, validate on 1107 samples\n",
      "Epoch 1/10\n",
      "4432/4432 [==============================] - 67s 15ms/step - loss: 0.2378 - acc: 0.9061 - val_loss: 0.1799 - val_acc: 0.9259\n",
      "Epoch 2/10\n",
      "4432/4432 [==============================] - 15s 3ms/step - loss: 0.1467 - acc: 0.9474 - val_loss: 0.1156 - val_acc: 0.9675\n",
      "Epoch 3/10\n",
      "4432/4432 [==============================] - 14s 3ms/step - loss: 0.1384 - acc: 0.9481 - val_loss: 0.1643 - val_acc: 0.9313\n",
      "Epoch 4/10\n",
      "4432/4432 [==============================] - 14s 3ms/step - loss: 0.1341 - acc: 0.9497 - val_loss: 0.1702 - val_acc: 0.9313\n",
      "Epoch 5/10\n",
      "4432/4432 [==============================] - 15s 3ms/step - loss: 0.1332 - acc: 0.9499 - val_loss: 0.1837 - val_acc: 0.9277\n",
      "Epoch 6/10\n",
      "4432/4432 [==============================] - 15s 3ms/step - loss: 0.1298 - acc: 0.9501 - val_loss: 0.1665 - val_acc: 0.9377\n",
      "Epoch 7/10\n",
      "4432/4432 [==============================] - 15s 3ms/step - loss: 0.1310 - acc: 0.9515 - val_loss: 0.1714 - val_acc: 0.9350\n",
      "Epoch 8/10\n",
      "4432/4432 [==============================] - 15s 3ms/step - loss: 0.1282 - acc: 0.9495 - val_loss: 0.1544 - val_acc: 0.9395\n",
      "Epoch 9/10\n",
      "4432/4432 [==============================] - 15s 3ms/step - loss: 0.1265 - acc: 0.9508 - val_loss: 0.1383 - val_acc: 0.9458\n",
      "Epoch 10/10\n",
      "4432/4432 [==============================] - 15s 3ms/step - loss: 0.1266 - acc: 0.9501 - val_loss: 0.1567 - val_acc: 0.9548\n",
      "1107/1107 [==============================] - 1s 875us/step\n",
      "delta: 6\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3945, 20)\n",
      "x_test shape: (986, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_38 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_100 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_101 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3945 samples, validate on 986 samples\n",
      "Epoch 1/10\n",
      "3945/3945 [==============================] - 54s 14ms/step - loss: 0.2415 - acc: 0.9108 - val_loss: 0.0935 - val_acc: 0.9513\n",
      "Epoch 2/10\n",
      "3945/3945 [==============================] - 13s 3ms/step - loss: 0.1527 - acc: 0.9463 - val_loss: 0.1730 - val_acc: 0.9219\n",
      "Epoch 3/10\n",
      "3945/3945 [==============================] - 13s 3ms/step - loss: 0.1423 - acc: 0.9478 - val_loss: 0.1396 - val_acc: 0.9391\n",
      "Epoch 4/10\n",
      "3945/3945 [==============================] - 13s 3ms/step - loss: 0.1351 - acc: 0.9490 - val_loss: 0.1681 - val_acc: 0.9300\n",
      "Epoch 5/10\n",
      "3945/3945 [==============================] - 13s 3ms/step - loss: 0.1336 - acc: 0.9485 - val_loss: 0.1549 - val_acc: 0.9381\n",
      "Epoch 6/10\n",
      "3945/3945 [==============================] - 13s 3ms/step - loss: 0.1299 - acc: 0.9501 - val_loss: 0.1934 - val_acc: 0.9320\n",
      "Epoch 7/10\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 0.1297 - acc: 0.9526 - val_loss: 0.1441 - val_acc: 0.9473\n",
      "Epoch 8/10\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 0.1262 - acc: 0.9539 - val_loss: 0.1450 - val_acc: 0.9574\n",
      "Epoch 9/10\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 0.1260 - acc: 0.9534 - val_loss: 0.1562 - val_acc: 0.9493\n",
      "Epoch 10/10\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 0.1255 - acc: 0.9546 - val_loss: 0.2007 - val_acc: 0.9351\n",
      "986/986 [==============================] - 1s 754us/step\n",
      "delta: 7\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3573, 20)\n",
      "x_test shape: (893, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_102 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_103 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3573 samples, validate on 893 samples\n",
      "Epoch 1/10\n",
      "3573/3573 [==============================] - 52s 15ms/step - loss: 0.2387 - acc: 0.9037 - val_loss: 0.1662 - val_acc: 0.9328\n",
      "Epoch 2/10\n",
      "3573/3573 [==============================] - 11s 3ms/step - loss: 0.1501 - acc: 0.9457 - val_loss: 0.1325 - val_acc: 0.9619\n",
      "Epoch 3/10\n",
      "3573/3573 [==============================] - 11s 3ms/step - loss: 0.1428 - acc: 0.9482 - val_loss: 0.1694 - val_acc: 0.9362\n",
      "Epoch 4/10\n",
      "3573/3573 [==============================] - 11s 3ms/step - loss: 0.1362 - acc: 0.9496 - val_loss: 0.1790 - val_acc: 0.9216\n",
      "Epoch 5/10\n",
      "3573/3573 [==============================] - 11s 3ms/step - loss: 0.1329 - acc: 0.9499 - val_loss: 0.1636 - val_acc: 0.9250s: \n",
      "Epoch 6/10\n",
      "3573/3573 [==============================] - 11s 3ms/step - loss: 0.1305 - acc: 0.9496 - val_loss: 0.1949 - val_acc: 0.9171\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3573/3573 [==============================] - 10s 3ms/step - loss: 0.1282 - acc: 0.9530 - val_loss: 0.2263 - val_acc: 0.9115\n",
      "Epoch 8/10\n",
      "3573/3573 [==============================] - 10s 3ms/step - loss: 0.1265 - acc: 0.9524 - val_loss: 0.1597 - val_acc: 0.9451\n",
      "Epoch 9/10\n",
      "3573/3573 [==============================] - 10s 3ms/step - loss: 0.1257 - acc: 0.9527 - val_loss: 0.1611 - val_acc: 0.9462\n",
      "Epoch 10/10\n",
      "3573/3573 [==============================] - 10s 3ms/step - loss: 0.1250 - acc: 0.9524 - val_loss: 0.1666 - val_acc: 0.9474\n",
      "893/893 [==============================] - 1s 682us/step\n",
      "delta: 8\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3275, 20)\n",
      "x_test shape: (818, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_104 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_105 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3275 samples, validate on 818 samples\n",
      "Epoch 1/10\n",
      "3275/3275 [==============================] - 54s 17ms/step - loss: 0.2517 - acc: 0.9060 - val_loss: 0.1480 - val_acc: 0.9633\n",
      "Epoch 2/10\n",
      "3275/3275 [==============================] - 11s 3ms/step - loss: 0.1540 - acc: 0.9456 - val_loss: 0.1654 - val_acc: 0.9401\n",
      "Epoch 3/10\n",
      "3275/3275 [==============================] - 11s 3ms/step - loss: 0.1418 - acc: 0.9469 - val_loss: 0.1273 - val_acc: 0.9499\n",
      "Epoch 4/10\n",
      "3275/3275 [==============================] - 12s 4ms/step - loss: 0.1385 - acc: 0.9481 - val_loss: 0.1142 - val_acc: 0.9694\n",
      "Epoch 5/10\n",
      "3275/3275 [==============================] - 11s 3ms/step - loss: 0.1350 - acc: 0.9502 - val_loss: 0.1610 - val_acc: 0.9413\n",
      "Epoch 6/10\n",
      "3275/3275 [==============================] - 11s 3ms/step - loss: 0.1339 - acc: 0.9518 - val_loss: 0.1217 - val_acc: 0.9658\n",
      "Epoch 7/10\n",
      "3275/3275 [==============================] - 11s 3ms/step - loss: 0.1326 - acc: 0.9518 - val_loss: 0.1232 - val_acc: 0.9548\n",
      "Epoch 8/10\n",
      "3275/3275 [==============================] - 11s 3ms/step - loss: 0.1325 - acc: 0.9530 - val_loss: 0.1804 - val_acc: 0.9328\n",
      "Epoch 9/10\n",
      "3275/3275 [==============================] - 11s 3ms/step - loss: 0.1295 - acc: 0.9521 - val_loss: 0.1468 - val_acc: 0.9597\n",
      "Epoch 10/10\n",
      "3275/3275 [==============================] - 11s 3ms/step - loss: 0.1266 - acc: 0.9539 - val_loss: 0.1380 - val_acc: 0.9597\n",
      "818/818 [==============================] - 1s 862us/step\n",
      "delta: 9\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2997, 20)\n",
      "x_test shape: (749, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_41 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_106 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_107 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 2997 samples, validate on 749 samples\n",
      "Epoch 1/10\n",
      "2997/2997 [==============================] - 58s 20ms/step - loss: 0.2619 - acc: 0.8926 - val_loss: 0.1350 - val_acc: 0.9720\n",
      "Epoch 2/10\n",
      "2997/2997 [==============================] - 11s 4ms/step - loss: 0.1544 - acc: 0.9459 - val_loss: 0.1235 - val_acc: 0.9599\n",
      "Epoch 3/10\n",
      "2997/2997 [==============================] - 11s 4ms/step - loss: 0.1440 - acc: 0.9443 - val_loss: 0.1309 - val_acc: 0.9493\n",
      "Epoch 4/10\n",
      "2997/2997 [==============================] - 11s 4ms/step - loss: 0.1386 - acc: 0.9496 - val_loss: 0.1218 - val_acc: 0.9626\n",
      "Epoch 5/10\n",
      "2997/2997 [==============================] - 11s 4ms/step - loss: 0.1334 - acc: 0.9513 - val_loss: 0.1204 - val_acc: 0.9613\n",
      "Epoch 6/10\n",
      "2997/2997 [==============================] - 11s 4ms/step - loss: 0.1307 - acc: 0.9520 - val_loss: 0.1579 - val_acc: 0.9559\n",
      "Epoch 7/10\n",
      "2997/2997 [==============================] - 11s 4ms/step - loss: 0.1300 - acc: 0.9523 - val_loss: 0.1257 - val_acc: 0.9506\n",
      "Epoch 8/10\n",
      "2997/2997 [==============================] - 15s 5ms/step - loss: 0.1289 - acc: 0.9523 - val_loss: 0.1442 - val_acc: 0.9613\n",
      "Epoch 9/10\n",
      "2997/2997 [==============================] - 12s 4ms/step - loss: 0.1274 - acc: 0.9533 - val_loss: 0.1554 - val_acc: 0.9466\n",
      "Epoch 10/10\n",
      "2997/2997 [==============================] - 12s 4ms/step - loss: 0.1263 - acc: 0.9550 - val_loss: 0.1362 - val_acc: 0.9573\n",
      "749/749 [==============================] - 1s 1ms/step\n",
      "  delta(min)    #train    #test    train loss(last)    train_acc(last)    val loss     val acc\n",
      "------------  --------  -------  ------------------  -----------------  -----------  ---------\n",
      "           1     11618     2904            0.147251           0.940179     0.175654   0.925275\n",
      "           2      7737     1934            0.132755           0.949981     0.169371   0.922441\n",
      "           3      6047     1511            0.13276            0.948404     0.185297   0.944408\n",
      "           4      5078     1269            0.128771           0.950571     0.158025   0.947991\n",
      "           5      4432     1107            0.126642           0.950135     0.156655   0.954833\n",
      "           6      3945      986            0.125495           0.954626     0.200732   0.935091\n",
      "           7      3573      893            0.12496            0.952421     0.166621   0.947368\n",
      "           8      3275      818            0.126601           0.953893     0.137987   0.959658\n",
      "           9      2997      749            0.126309           0.954955     0.136151   0.957276\n",
      "results: [[1, 11618, 2904, 0.14725120341939793, 0.9401790325357204, 0.1756541792729218, 0.925275482093664], [2, 7737, 1934, 0.13275476368581107, 0.9499806125712238, 0.1693714380160989, 0.922440537745605], [3, 6047, 1511, 0.1327596895337568, 0.9484041673557135, 0.1852967034908866, 0.9444076770350761], [4, 5078, 1269, 0.12877135054186697, 0.9505710909102741, 0.1580245637022424, 0.9479905437352246], [5, 4432, 1107, 0.1266418857439438, 0.9501353790613718, 0.15665543486380276, 0.95483288166215], [6, 3945, 986, 0.12549513047738106, 0.9546261089987326, 0.20073225349854937, 0.9350912778904665], [7, 3573, 893, 0.12496015952684751, 0.9524209347886929, 0.16662133094794163, 0.9473684210526315], [8, 3275, 818, 0.12660065178766505, 0.9538931297709924, 0.13798702298478543, 0.9596577017114915], [9, 2997, 749, 0.1263086666559075, 0.9549549549748431, 0.13615068477658196, 0.9572763684913218]]\n",
      "number_of_lstm_layers: 3\n",
      "delta: 1\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (11618, 20)\n",
      "x_test shape: (2904, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_42 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_108 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_109 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_110 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 11618 samples, validate on 2904 samples\n",
      "Epoch 1/10\n",
      "11618/11618 [==============================] - 882s 76ms/step - loss: 0.2319 - acc: 0.9046 - val_loss: 0.3447 - val_acc: 0.8826\n",
      "Epoch 2/10\n",
      "11618/11618 [==============================] - 57s 5ms/step - loss: 0.1622 - acc: 0.9340 - val_loss: 0.2010 - val_acc: 0.9101\n",
      "Epoch 3/10\n",
      "11618/11618 [==============================] - 57s 5ms/step - loss: 0.1565 - acc: 0.9346 - val_loss: 0.2378 - val_acc: 0.8994\n",
      "Epoch 4/10\n",
      "11618/11618 [==============================] - 61s 5ms/step - loss: 0.1545 - acc: 0.9378 - val_loss: 0.2131 - val_acc: 0.9060\n",
      "Epoch 5/10\n",
      "11618/11618 [==============================] - 61s 5ms/step - loss: 0.1528 - acc: 0.9381 - val_loss: 0.2072 - val_acc: 0.9077\n",
      "Epoch 6/10\n",
      "11618/11618 [==============================] - 61s 5ms/step - loss: 0.1514 - acc: 0.9402 - val_loss: 0.1715 - val_acc: 0.9456\n",
      "Epoch 7/10\n",
      "11618/11618 [==============================] - 60s 5ms/step - loss: 0.1486 - acc: 0.9406 - val_loss: 0.1842 - val_acc: 0.9191\n",
      "Epoch 8/10\n",
      "11618/11618 [==============================] - 60s 5ms/step - loss: 0.1493 - acc: 0.9404 - val_loss: 0.1976 - val_acc: 0.9132\n",
      "Epoch 9/10\n",
      "11618/11618 [==============================] - 63s 5ms/step - loss: 0.1485 - acc: 0.9404 - val_loss: 0.2347 - val_acc: 0.8974\n",
      "Epoch 10/10\n",
      "11618/11618 [==============================] - 60s 5ms/step - loss: 0.1471 - acc: 0.9404 - val_loss: 0.2079 - val_acc: 0.9001\n",
      "2904/2904 [==============================] - 4s 1ms/step\n",
      "delta: 2\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (7737, 20)\n",
      "x_test shape: (1934, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_43 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_111 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_112 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_113 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 7737 samples, validate on 1934 samples\n",
      "Epoch 1/10\n",
      "7737/7737 [==============================] - 127s 16ms/step - loss: 0.2317 - acc: 0.9076 - val_loss: 0.1474 - val_acc: 0.9359\n",
      "Epoch 2/10\n",
      "7737/7737 [==============================] - 36s 5ms/step - loss: 0.1513 - acc: 0.9409 - val_loss: 0.1822 - val_acc: 0.9214\n",
      "Epoch 3/10\n",
      "7737/7737 [==============================] - 36s 5ms/step - loss: 0.1460 - acc: 0.9443 - val_loss: 0.1659 - val_acc: 0.9147\n",
      "Epoch 4/10\n",
      "7737/7737 [==============================] - 38s 5ms/step - loss: 0.1425 - acc: 0.9458 - val_loss: 0.1756 - val_acc: 0.9369\n",
      "Epoch 5/10\n",
      "7737/7737 [==============================] - 37s 5ms/step - loss: 0.1411 - acc: 0.9449 - val_loss: 0.2234 - val_acc: 0.9018\n",
      "Epoch 6/10\n",
      "7737/7737 [==============================] - 37s 5ms/step - loss: 0.1391 - acc: 0.9461 - val_loss: 0.2219 - val_acc: 0.9049\n",
      "Epoch 7/10\n",
      "7737/7737 [==============================] - 37s 5ms/step - loss: 0.1383 - acc: 0.9475 - val_loss: 0.1480 - val_acc: 0.9623\n",
      "Epoch 8/10\n",
      "7737/7737 [==============================] - 37s 5ms/step - loss: 0.1356 - acc: 0.9462 - val_loss: 0.2198 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "7737/7737 [==============================] - 37s 5ms/step - loss: 0.1362 - acc: 0.9480 - val_loss: 0.1664 - val_acc: 0.9317\n",
      "Epoch 10/10\n",
      "7737/7737 [==============================] - 39s 5ms/step - loss: 0.1347 - acc: 0.9480 - val_loss: 0.1809 - val_acc: 0.9328\n",
      "1934/1934 [==============================] - 3s 1ms/step\n",
      "delta: 3\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (6047, 20)\n",
      "x_test shape: (1511, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_44 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_114 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_115 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_116 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 6047 samples, validate on 1511 samples\n",
      "Epoch 1/10\n",
      "6047/6047 [==============================] - 117s 19ms/step - loss: 0.2415 - acc: 0.9047 - val_loss: 0.1661 - val_acc: 0.9279\n",
      "Epoch 2/10\n",
      "6047/6047 [==============================] - 29s 5ms/step - loss: 0.1507 - acc: 0.9425 - val_loss: 0.1529 - val_acc: 0.9385\n",
      "Epoch 3/10\n",
      "6047/6047 [==============================] - 30s 5ms/step - loss: 0.1456 - acc: 0.9441 - val_loss: 0.2188 - val_acc: 0.9146\n",
      "Epoch 4/10\n",
      "6047/6047 [==============================] - 30s 5ms/step - loss: 0.1411 - acc: 0.9456 - val_loss: 0.1501 - val_acc: 0.9543\n",
      "Epoch 5/10\n",
      "6047/6047 [==============================] - 32s 5ms/step - loss: 0.1402 - acc: 0.9446 - val_loss: 0.1526 - val_acc: 0.9610\n",
      "Epoch 6/10\n",
      "6047/6047 [==============================] - 30s 5ms/step - loss: 0.1358 - acc: 0.9477 - val_loss: 0.1832 - val_acc: 0.9332\n",
      "Epoch 7/10\n",
      "6047/6047 [==============================] - 30s 5ms/step - loss: 0.1348 - acc: 0.9481 - val_loss: 0.1732 - val_acc: 0.9490\n",
      "Epoch 8/10\n",
      "6047/6047 [==============================] - 30s 5ms/step - loss: 0.1353 - acc: 0.9482 - val_loss: 0.2112 - val_acc: 0.9219\n",
      "Epoch 9/10\n",
      "6047/6047 [==============================] - 30s 5ms/step - loss: 0.1337 - acc: 0.9487 - val_loss: 0.2005 - val_acc: 0.9332\n",
      "Epoch 10/10\n",
      "6047/6047 [==============================] - 30s 5ms/step - loss: 0.1340 - acc: 0.9492 - val_loss: 0.1890 - val_acc: 0.9437\n",
      "1511/1511 [==============================] - 2s 1ms/step\n",
      "delta: 4\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (5078, 20)\n",
      "x_test shape: (1269, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_45 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_117 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_118 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_119 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 5078 samples, validate on 1269 samples\n",
      "Epoch 1/10\n",
      "5078/5078 [==============================] - 234s 46ms/step - loss: 0.2512 - acc: 0.8984 - val_loss: 0.1733 - val_acc: 0.9322\n",
      "Epoch 2/10\n",
      "5078/5078 [==============================] - 25s 5ms/step - loss: 0.1522 - acc: 0.9403 - val_loss: 0.1534 - val_acc: 0.9559\n",
      "Epoch 3/10\n",
      "5078/5078 [==============================] - 27s 5ms/step - loss: 0.1437 - acc: 0.9451 - val_loss: 0.1795 - val_acc: 0.9322\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5078/5078 [==============================] - 25s 5ms/step - loss: 0.1377 - acc: 0.9472 - val_loss: 0.1699 - val_acc: 0.9535\n",
      "Epoch 5/10\n",
      "5078/5078 [==============================] - 25s 5ms/step - loss: 0.1356 - acc: 0.9480 - val_loss: 0.1560 - val_acc: 0.9417\n",
      "Epoch 6/10\n",
      "5078/5078 [==============================] - 25s 5ms/step - loss: 0.1357 - acc: 0.9478 - val_loss: 0.1387 - val_acc: 0.9504\n",
      "Epoch 7/10\n",
      "5078/5078 [==============================] - 25s 5ms/step - loss: 0.1341 - acc: 0.9496 - val_loss: 0.1519 - val_acc: 0.9590\n",
      "Epoch 8/10\n",
      "5078/5078 [==============================] - 26s 5ms/step - loss: 0.1323 - acc: 0.9516 - val_loss: 0.1652 - val_acc: 0.9464\n",
      "Epoch 9/10\n",
      "5078/5078 [==============================] - 25s 5ms/step - loss: 0.1304 - acc: 0.9488 - val_loss: 0.1417 - val_acc: 0.9433\n",
      "Epoch 10/10\n",
      "5078/5078 [==============================] - 25s 5ms/step - loss: 0.1297 - acc: 0.9514 - val_loss: 0.1456 - val_acc: 0.9535\n",
      "1269/1269 [==============================] - 2s 1ms/step\n",
      "delta: 5\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (4432, 20)\n",
      "x_test shape: (1107, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_46 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_120 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_121 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_122 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 4432 samples, validate on 1107 samples\n",
      "Epoch 1/10\n",
      "4432/4432 [==============================] - 103s 23ms/step - loss: 0.2559 - acc: 0.8976 - val_loss: 0.1252 - val_acc: 0.9693\n",
      "Epoch 2/10\n",
      "4432/4432 [==============================] - 21s 5ms/step - loss: 0.1547 - acc: 0.9449 - val_loss: 0.2398 - val_acc: 0.8907\n",
      "Epoch 3/10\n",
      "4432/4432 [==============================] - 23s 5ms/step - loss: 0.1427 - acc: 0.9463 - val_loss: 0.1416 - val_acc: 0.9359\n",
      "Epoch 4/10\n",
      "4432/4432 [==============================] - 23s 5ms/step - loss: 0.1388 - acc: 0.9463 - val_loss: 0.1507 - val_acc: 0.9368\n",
      "Epoch 5/10\n",
      "4432/4432 [==============================] - 23s 5ms/step - loss: 0.1354 - acc: 0.9504 - val_loss: 0.1331 - val_acc: 0.9404\n",
      "Epoch 6/10\n",
      "4432/4432 [==============================] - 23s 5ms/step - loss: 0.1352 - acc: 0.9499 - val_loss: 0.1328 - val_acc: 0.9666\n",
      "Epoch 7/10\n",
      "4432/4432 [==============================] - 24s 5ms/step - loss: 0.1311 - acc: 0.9490 - val_loss: 0.1652 - val_acc: 0.9530\n",
      "Epoch 8/10\n",
      "4432/4432 [==============================] - 24s 5ms/step - loss: 0.1288 - acc: 0.9513 - val_loss: 0.1523 - val_acc: 0.9503\n",
      "Epoch 9/10\n",
      "4432/4432 [==============================] - 27s 6ms/step - loss: 0.1308 - acc: 0.9506 - val_loss: 0.1300 - val_acc: 0.9675\n",
      "Epoch 10/10\n",
      "4432/4432 [==============================] - 24s 5ms/step - loss: 0.1309 - acc: 0.9522 - val_loss: 0.1919 - val_acc: 0.9304\n",
      "1107/1107 [==============================] - 1s 1ms/step\n",
      "delta: 6\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3945, 20)\n",
      "x_test shape: (986, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_47 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_123 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_124 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_125 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3945 samples, validate on 986 samples\n",
      "Epoch 1/10\n",
      "  64/3945 [..............................] - ETA: 1:41:35 - loss: 0.6876 - acc: 0.5781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37_64\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.295507). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3945/3945 [==============================] - 148s 38ms/step - loss: 0.2625 - acc: 0.8935 - val_loss: 0.1784 - val_acc: 0.9300\n",
      "Epoch 2/10\n",
      "3945/3945 [==============================] - 19s 5ms/step - loss: 0.1575 - acc: 0.9490 - val_loss: 0.1632 - val_acc: 0.9381\n",
      "Epoch 3/10\n",
      "3945/3945 [==============================] - 19s 5ms/step - loss: 0.1442 - acc: 0.9490 - val_loss: 0.1412 - val_acc: 0.9381\n",
      "Epoch 4/10\n",
      "3945/3945 [==============================] - 20s 5ms/step - loss: 0.1385 - acc: 0.9473 - val_loss: 0.1526 - val_acc: 0.9513\n",
      "Epoch 5/10\n",
      "3945/3945 [==============================] - 20s 5ms/step - loss: 0.1355 - acc: 0.9496 - val_loss: 0.1490 - val_acc: 0.9544\n",
      "Epoch 6/10\n",
      "3945/3945 [==============================] - 21s 5ms/step - loss: 0.1332 - acc: 0.9501 - val_loss: 0.1684 - val_acc: 0.9442\n",
      "Epoch 7/10\n",
      "3945/3945 [==============================] - 21s 5ms/step - loss: 0.1332 - acc: 0.9501 - val_loss: 0.1792 - val_acc: 0.9331\n",
      "Epoch 8/10\n",
      "3945/3945 [==============================] - 20s 5ms/step - loss: 0.1286 - acc: 0.9518 - val_loss: 0.1778 - val_acc: 0.9442\n",
      "Epoch 9/10\n",
      "3945/3945 [==============================] - 21s 5ms/step - loss: 0.1283 - acc: 0.9516 - val_loss: 0.2025 - val_acc: 0.9270\n",
      "Epoch 10/10\n",
      "3945/3945 [==============================] - 21s 5ms/step - loss: 0.1273 - acc: 0.9508 - val_loss: 0.1444 - val_acc: 0.9503\n",
      "986/986 [==============================] - 1s 1ms/step\n",
      "delta: 7\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3573, 20)\n",
      "x_test shape: (893, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_48 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_126 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_127 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_128 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3573 samples, validate on 893 samples\n",
      "Epoch 1/10\n",
      "3573/3573 [==============================] - 117s 33ms/step - loss: 0.2745 - acc: 0.8917 - val_loss: 0.1531 - val_acc: 0.9351\n",
      "Epoch 2/10\n",
      "3573/3573 [==============================] - 16s 5ms/step - loss: 0.1590 - acc: 0.9437 - val_loss: 0.2097 - val_acc: 0.9171\n",
      "Epoch 3/10\n",
      "3573/3573 [==============================] - 17s 5ms/step - loss: 0.1418 - acc: 0.9485 - val_loss: 0.1840 - val_acc: 0.9429\n",
      "Epoch 4/10\n",
      "3573/3573 [==============================] - 18s 5ms/step - loss: 0.1391 - acc: 0.9499 - val_loss: 0.1283 - val_acc: 0.9608\n",
      "Epoch 5/10\n",
      "3573/3573 [==============================] - 18s 5ms/step - loss: 0.1340 - acc: 0.9499 - val_loss: 0.1715 - val_acc: 0.9451\n",
      "Epoch 6/10\n",
      "3573/3573 [==============================] - 18s 5ms/step - loss: 0.1310 - acc: 0.9524 - val_loss: 0.1242 - val_acc: 0.9686\n",
      "Epoch 7/10\n",
      "3573/3573 [==============================] - 18s 5ms/step - loss: 0.1320 - acc: 0.9527 - val_loss: 0.2179 - val_acc: 0.9250\n",
      "Epoch 8/10\n",
      "3573/3573 [==============================] - 18s 5ms/step - loss: 0.1299 - acc: 0.9530 - val_loss: 0.1805 - val_acc: 0.9429\n",
      "Epoch 9/10\n",
      "3573/3573 [==============================] - 18s 5ms/step - loss: 0.1276 - acc: 0.9547 - val_loss: 0.1370 - val_acc: 0.9541\n",
      "Epoch 10/10\n",
      "3573/3573 [==============================] - 19s 5ms/step - loss: 0.1262 - acc: 0.9516 - val_loss: 0.1622 - val_acc: 0.9507\n",
      "893/893 [==============================] - 1s 1ms/step\n",
      "delta: 8\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3275, 20)\n",
      "x_test shape: (818, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_49 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_129 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_130 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_131 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3275 samples, validate on 818 samples\n",
      "Epoch 1/10\n",
      "3275/3275 [==============================] - 168s 51ms/step - loss: 0.2679 - acc: 0.8919 - val_loss: 0.1454 - val_acc: 0.9425\n",
      "Epoch 2/10\n",
      "3275/3275 [==============================] - 16s 5ms/step - loss: 0.1614 - acc: 0.9420 - val_loss: 0.1222 - val_acc: 0.9609\n",
      "Epoch 3/10\n",
      "3275/3275 [==============================] - 15s 5ms/step - loss: 0.1466 - acc: 0.9496 - val_loss: 0.1435 - val_acc: 0.9487\n",
      "Epoch 4/10\n",
      "3275/3275 [==============================] - 16s 5ms/step - loss: 0.1422 - acc: 0.9493 - val_loss: 0.1406 - val_acc: 0.9645\n",
      "Epoch 5/10\n",
      "3275/3275 [==============================] - 17s 5ms/step - loss: 0.1393 - acc: 0.9499 - val_loss: 0.1257 - val_acc: 0.9474\n",
      "Epoch 6/10\n",
      "3275/3275 [==============================] - 17s 5ms/step - loss: 0.1350 - acc: 0.9518 - val_loss: 0.1922 - val_acc: 0.9303\n",
      "Epoch 7/10\n",
      "3275/3275 [==============================] - 17s 5ms/step - loss: 0.1342 - acc: 0.9490 - val_loss: 0.1461 - val_acc: 0.9523\n",
      "Epoch 8/10\n",
      "3275/3275 [==============================] - 17s 5ms/step - loss: 0.1324 - acc: 0.9539 - val_loss: 0.1249 - val_acc: 0.9682\n",
      "Epoch 9/10\n",
      "3275/3275 [==============================] - 17s 5ms/step - loss: 0.1324 - acc: 0.9511 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 10/10\n",
      "3275/3275 [==============================] - 17s 5ms/step - loss: 0.1303 - acc: 0.9533 - val_loss: 0.1488 - val_acc: 0.9621\n",
      "818/818 [==============================] - 1s 1ms/step\n",
      "delta: 9\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2997, 20)\n",
      "x_test shape: (749, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_50 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_132 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_133 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_134 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 2997 samples, validate on 749 samples\n",
      "Epoch 1/10\n",
      "2997/2997 [==============================] - 142s 47ms/step - loss: 0.2853 - acc: 0.8809 - val_loss: 0.1860 - val_acc: 0.9466\n",
      "Epoch 2/10\n",
      "2997/2997 [==============================] - 19s 6ms/step - loss: 0.1648 - acc: 0.9399 - val_loss: 0.1473 - val_acc: 0.9586\n",
      "Epoch 3/10\n",
      "2997/2997 [==============================] - 19s 6ms/step - loss: 0.1475 - acc: 0.9426 - val_loss: 0.1006 - val_acc: 0.9666\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2997/2997 [==============================] - 19s 6ms/step - loss: 0.1373 - acc: 0.9499 - val_loss: 0.1982 - val_acc: 0.9212\n",
      "Epoch 5/10\n",
      "2997/2997 [==============================] - 20s 7ms/step - loss: 0.1340 - acc: 0.9496 - val_loss: 0.1267 - val_acc: 0.9573\n",
      "Epoch 6/10\n",
      "2997/2997 [==============================] - 20s 7ms/step - loss: 0.1358 - acc: 0.9513 - val_loss: 0.1384 - val_acc: 0.9533\n",
      "Epoch 7/10\n",
      "2997/2997 [==============================] - 20s 7ms/step - loss: 0.1317 - acc: 0.9533 - val_loss: 0.1707 - val_acc: 0.9372\n",
      "Epoch 8/10\n",
      "2997/2997 [==============================] - 20s 7ms/step - loss: 0.1307 - acc: 0.9516 - val_loss: 0.1687 - val_acc: 0.9546\n",
      "Epoch 9/10\n",
      "2997/2997 [==============================] - 20s 7ms/step - loss: 0.1292 - acc: 0.9530 - val_loss: 0.1517 - val_acc: 0.9613\n",
      "Epoch 10/10\n",
      "2997/2997 [==============================] - 20s 7ms/step - loss: 0.1276 - acc: 0.9533 - val_loss: 0.1543 - val_acc: 0.9466\n",
      "749/749 [==============================] - 1s 2ms/step\n",
      "  delta(min)    #train    #test    train loss(last)    train_acc(last)    val loss     val acc\n",
      "------------  --------  -------  ------------------  -----------------  -----------  ---------\n",
      "           1     11618     2904            0.147149           0.940351     0.207893   0.900138\n",
      "           2      7737     1934            0.134669           0.948042     0.180884   0.932782\n",
      "           3      6047     1511            0.133969           0.949231     0.188952   0.943746\n",
      "           4      5078     1269            0.129656           0.951359     0.145592   0.953507\n",
      "           5      4432     1107            0.13086            0.952166     0.191892   0.930443\n",
      "           6      3945      986            0.127251           0.950824     0.144433   0.950304\n",
      "           7      3573      893            0.126193           0.951581     0.162221   0.950728\n",
      "           8      3275      818            0.130265           0.953282     0.148819   0.962103\n",
      "           9      2997      749            0.127609           0.953287     0.154284   0.946595\n",
      "results: [[1, 11618, 2904, 0.14714891581709053, 0.9403511792046824, 0.20789310575293546, 0.900137741046832], [2, 7737, 1934, 0.13466891488841573, 0.9480418767503208, 0.1808840798149309, 0.9327817993795243], [3, 6047, 1511, 0.13396932436539868, 0.9492310235002366, 0.1889520411285332, 0.9437458636664461], [4, 5078, 1269, 0.12965605478673622, 0.9513588026077928, 0.1455922620084762, 0.9535066981875493], [5, 4432, 1107, 0.1308598727280348, 0.9521660649819494, 0.19189225109376085, 0.9304426377597109], [6, 3945, 986, 0.12725132954589014, 0.9508238276601291, 0.14443303226187737, 0.9503042596348884], [7, 3573, 893, 0.12619275217492673, 0.9515813042261405, 0.1622206661328105, 0.9507278835386338], [8, 3275, 818, 0.13026513862700861, 0.953282442839091, 0.14881942008051585, 0.9621026894865525], [9, 2997, 749, 0.127609123885731, 0.9532866199930629, 0.15428417717040271, 0.9465954606141522]]\n",
      "number_of_lstm_layers: 4\n",
      "delta: 1\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (11618, 20)\n",
      "x_test shape: (2904, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_51 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_135 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_136 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_137 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_138 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 11618 samples, validate on 2904 samples\n",
      "Epoch 1/10\n",
      "11618/11618 [==============================] - 1254s 108ms/step - loss: 0.2433 - acc: 0.8964 - val_loss: 0.4309 - val_acc: 0.8048\n",
      "Epoch 2/10\n",
      "11618/11618 [==============================] - 80s 7ms/step - loss: 0.1654 - acc: 0.9330 - val_loss: 0.1509 - val_acc: 0.9604\n",
      "Epoch 3/10\n",
      "11618/11618 [==============================] - 84s 7ms/step - loss: 0.1603 - acc: 0.9351 - val_loss: 0.1973 - val_acc: 0.9077\n",
      "Epoch 4/10\n",
      "11618/11618 [==============================] - 85s 7ms/step - loss: 0.1560 - acc: 0.9379 - val_loss: 0.2005 - val_acc: 0.9360\n",
      "Epoch 5/10\n",
      "11618/11618 [==============================] - 84s 7ms/step - loss: 0.1549 - acc: 0.9390 - val_loss: 0.1753 - val_acc: 0.9511\n",
      "Epoch 6/10\n",
      "11618/11618 [==============================] - 83s 7ms/step - loss: 0.1547 - acc: 0.9405 - val_loss: 0.2214 - val_acc: 0.9036\n",
      "Epoch 7/10\n",
      "11618/11618 [==============================] - 83s 7ms/step - loss: 0.1531 - acc: 0.9384 - val_loss: 0.1893 - val_acc: 0.9322\n",
      "Epoch 8/10\n",
      "11618/11618 [==============================] - 83s 7ms/step - loss: 0.1525 - acc: 0.9391 - val_loss: 0.2340 - val_acc: 0.9060\n",
      "Epoch 9/10\n",
      "11618/11618 [==============================] - 83s 7ms/step - loss: 0.1510 - acc: 0.9406 - val_loss: 0.2108 - val_acc: 0.9132\n",
      "Epoch 10/10\n",
      "11618/11618 [==============================] - 83s 7ms/step - loss: 0.1497 - acc: 0.9410 - val_loss: 0.2012 - val_acc: 0.9191\n",
      "2904/2904 [==============================] - 6s 2ms/step\n",
      "delta: 2\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (7737, 20)\n",
      "x_test shape: (1934, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_52 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_139 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_140 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_141 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_142 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 7737 samples, validate on 1934 samples\n",
      "Epoch 1/10\n",
      "  64/7737 [..............................] - ETA: 8:08:01 - loss: 0.6932 - acc: 0.4688 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37_64\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.695207). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7737/7737 [==============================] - 348s 45ms/step - loss: 0.2551 - acc: 0.8949 - val_loss: 0.1868 - val_acc: 0.9271\n",
      "Epoch 2/10\n",
      "7737/7737 [==============================] - 55s 7ms/step - loss: 0.1557 - acc: 0.9407 - val_loss: 0.1828 - val_acc: 0.9126\n",
      "Epoch 3/10\n",
      "7737/7737 [==============================] - 57s 7ms/step - loss: 0.1477 - acc: 0.9446 - val_loss: 0.1953 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "7737/7737 [==============================] - 58s 8ms/step - loss: 0.1461 - acc: 0.9446 - val_loss: 0.1879 - val_acc: 0.9224\n",
      "Epoch 5/10\n",
      "7737/7737 [==============================] - 58s 7ms/step - loss: 0.1439 - acc: 0.9458 - val_loss: 0.1745 - val_acc: 0.9255\n",
      "Epoch 6/10\n",
      "7737/7737 [==============================] - 57s 7ms/step - loss: 0.1427 - acc: 0.9467 - val_loss: 0.1748 - val_acc: 0.9328\n",
      "Epoch 7/10\n",
      "7737/7737 [==============================] - 58s 7ms/step - loss: 0.1410 - acc: 0.9473 - val_loss: 0.1788 - val_acc: 0.9338\n",
      "Epoch 8/10\n",
      "7737/7737 [==============================] - 58s 7ms/step - loss: 0.1396 - acc: 0.9473 - val_loss: 0.1549 - val_acc: 0.9550\n",
      "Epoch 9/10\n",
      "7737/7737 [==============================] - 59s 8ms/step - loss: 0.1396 - acc: 0.9467 - val_loss: 0.1868 - val_acc: 0.9286\n",
      "Epoch 10/10\n",
      "7737/7737 [==============================] - 58s 7ms/step - loss: 0.1385 - acc: 0.9473 - val_loss: 0.2127 - val_acc: 0.9209\n",
      "1934/1934 [==============================] - 4s 2ms/step\n",
      "delta: 3\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (6047, 20)\n",
      "x_test shape: (1511, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_53 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_143 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_144 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_145 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_146 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 6047 samples, validate on 1511 samples\n",
      "Epoch 1/10\n",
      "  64/6047 [..............................] - ETA: 26:25:30 - loss: 0.6878 - acc: 0.5469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37_64\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.873560). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6047/6047 [==============================] - 1114s 184ms/step - loss: 0.2621 - acc: 0.8909 - val_loss: 0.1717 - val_acc: 0.9265\n",
      "Epoch 2/10\n",
      "6047/6047 [==============================] - 50s 8ms/step - loss: 0.1549 - acc: 0.9390 - val_loss: 0.1609 - val_acc: 0.9351\n",
      "Epoch 3/10\n",
      "6047/6047 [==============================] - 47s 8ms/step - loss: 0.1468 - acc: 0.9415 - val_loss: 0.1906 - val_acc: 0.9477\n",
      "Epoch 4/10\n",
      "6047/6047 [==============================] - 51s 8ms/step - loss: 0.1437 - acc: 0.9448 - val_loss: 0.1642 - val_acc: 0.9418\n",
      "Epoch 5/10\n",
      "6047/6047 [==============================] - 51s 8ms/step - loss: 0.1443 - acc: 0.9458 - val_loss: 0.1552 - val_acc: 0.9576\n",
      "Epoch 6/10\n",
      "6047/6047 [==============================] - 51s 8ms/step - loss: 0.1393 - acc: 0.9454 - val_loss: 0.1440 - val_acc: 0.9338\n",
      "Epoch 7/10\n",
      "6047/6047 [==============================] - 51s 8ms/step - loss: 0.1394 - acc: 0.9456 - val_loss: 0.1822 - val_acc: 0.9351\n",
      "Epoch 8/10\n",
      "6047/6047 [==============================] - 51s 8ms/step - loss: 0.1373 - acc: 0.9463 - val_loss: 0.1816 - val_acc: 0.9378\n",
      "Epoch 9/10\n",
      "6047/6047 [==============================] - 51s 8ms/step - loss: 0.1370 - acc: 0.9491 - val_loss: 0.1985 - val_acc: 0.9351\n",
      "Epoch 10/10\n",
      "6047/6047 [==============================] - 52s 9ms/step - loss: 0.1352 - acc: 0.9491 - val_loss: 0.1715 - val_acc: 0.9232\n",
      "1511/1511 [==============================] - 4s 2ms/step\n",
      "delta: 4\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (5078, 20)\n",
      "x_test shape: (1269, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_54 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_147 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_148 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_149 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_150 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 5078 samples, validate on 1269 samples\n",
      "Epoch 1/10\n",
      "5078/5078 [==============================] - 671s 132ms/step - loss: 0.2822 - acc: 0.8814 - val_loss: 0.1497 - val_acc: 0.9464\n",
      "Epoch 2/10\n",
      "5078/5078 [==============================] - 45s 9ms/step - loss: 0.1569 - acc: 0.9395 - val_loss: 0.1718 - val_acc: 0.9346\n",
      "Epoch 3/10\n",
      "5078/5078 [==============================] - 45s 9ms/step - loss: 0.1460 - acc: 0.9460 - val_loss: 0.1400 - val_acc: 0.9472\n",
      "Epoch 4/10\n",
      "5078/5078 [==============================] - 46s 9ms/step - loss: 0.1410 - acc: 0.9441 - val_loss: 0.1435 - val_acc: 0.9504\n",
      "Epoch 5/10\n",
      "5078/5078 [==============================] - 46s 9ms/step - loss: 0.1399 - acc: 0.9484 - val_loss: 0.1645 - val_acc: 0.9574\n",
      "Epoch 6/10\n",
      "5078/5078 [==============================] - 46s 9ms/step - loss: 0.1358 - acc: 0.9484 - val_loss: 0.1237 - val_acc: 0.9685\n",
      "Epoch 7/10\n",
      "5078/5078 [==============================] - 46s 9ms/step - loss: 0.1328 - acc: 0.9488 - val_loss: 0.1723 - val_acc: 0.9433\n",
      "Epoch 8/10\n",
      "5078/5078 [==============================] - 47s 9ms/step - loss: 0.1353 - acc: 0.9488 - val_loss: 0.1261 - val_acc: 0.9669\n",
      "Epoch 9/10\n",
      "5078/5078 [==============================] - 48s 9ms/step - loss: 0.1319 - acc: 0.9474 - val_loss: 0.1575 - val_acc: 0.9638\n",
      "Epoch 10/10\n",
      "5078/5078 [==============================] - 47s 9ms/step - loss: 0.1324 - acc: 0.9494 - val_loss: 0.1238 - val_acc: 0.9567\n",
      "1269/1269 [==============================] - 3s 3ms/step\n",
      "delta: 5\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (4432, 20)\n",
      "x_test shape: (1107, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_55 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_151 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_152 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_153 (LSTM)              (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_154 (LSTM)              (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 4432 samples, validate on 1107 samples\n",
      "Epoch 1/10\n",
      "  64/4432 [..............................] - ETA: 8:44:44 - loss: 0.6887 - acc: 0.5938 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37_64\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.565105). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4432/4432 [==============================] - 524s 118ms/step - loss: 0.2877 - acc: 0.8705 - val_loss: 0.1385 - val_acc: 0.9503\n",
      "Epoch 2/10\n",
      "2880/4432 [==================>...........] - ETA: 12s - loss: 0.1506 - acc: 0.9434"
     ]
    }
   ],
   "source": [
    "#address_to_read= r\"E:/pgmpy\\Twor2009\\Seq of sensor events_based on activities\\based_on_activities.csv\"\n",
    "address_to_read = r\"E:\\pgmpy\\Twor2009\\Seq of sensor events_no overlap_based on different deltas\\delta_{}min.csv\"\n",
    "#address_to_read = r\"E:\\pgmpy\\Twor2009\\Seq of sensor events_based_on_activity_and_no_overlap_delta\\delta_{}min.csv\"\n",
    "print(address_to_read)\n",
    "ID_of_layer_to_repeat = 0\n",
    "print(\"ID_of_layer_to_repeat:\" , ID_of_layer_to_repeat)\n",
    "results = select_hyperparameters(address_to_read = address_to_read , ID_of_layer_to_repeat = ID_of_layer_to_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d20da67344a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(results[:][-1])\n",
    "print(np.argmax(results[:][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (2578, 20)\n",
      "x_test shape: (644, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_104 (Embedding)    (None, None, 64)          7808      \n",
      "_________________________________________________________________\n",
      "gru_69 (GRU)                 (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 32,641\n",
      "Trainable params: 32,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 2578 samples, validate on 644 samples\n",
      "Epoch 1/5\n",
      "2578/2578 [==============================] - 68s 26ms/step - loss: 0.2978 - acc: 0.8798 - val_loss: 0.8843 - val_acc: 0.4953\n",
      "Epoch 2/5\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.1502 - acc: 0.9298 - val_loss: 0.7980 - val_acc: 0.7407\n",
      "Epoch 3/5\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.1279 - acc: 0.9422 - val_loss: 0.8525 - val_acc: 0.7516\n",
      "Epoch 4/5\n",
      "2578/2578 [==============================] - 5s 2ms/step - loss: 0.1234 - acc: 0.9476 - val_loss: 0.8574 - val_acc: 0.7593\n",
      "Epoch 5/5\n",
      "2578/2578 [==============================] - 6s 2ms/step - loss: 0.1192 - acc: 0.9488 - val_loss: 1.0502 - val_acc: 0.7174\n",
      "644/644 [==============================] - 1s 1ms/step\n",
      "Test score: 1.0502266776487694\n",
      "Test accuracy: 0.717391304347826\n",
      "test_score: 1.0502266776487694\n",
      "test_acc: 0.717391304347826\n",
      "history: {'val_loss': [0.8843139795042714, 0.797959275867628, 0.852543172258768, 0.8573945560810728, 1.0502266776487694], 'val_acc': [0.4953416149068323, 0.7406832298136646, 0.7515527950310559, 0.7593167701863354, 0.717391304347826], 'loss': [0.2977950490658555, 0.1501801671609109, 0.1279152952036347, 0.12335661232841394, 0.1192220518577922], 'acc': [0.8797517456316597, 0.9297905353449222, 0.9422032583397983, 0.947633824716528, 0.9487975174553918]}\n",
      "num_of_train_samples: 2578\n",
      "num_of_test_sample: 644\n"
     ]
    }
   ],
   "source": [
    "address_to_read= r\"E:/pgmpy/Twor2009/Seq of sensor events_based on activities/based_on_activities.csv\"\n",
    "\n",
    "x_train, x_test, y_train, y_test, max_features, maxlen = data_preparation_for_sequences_based_deep_models(address_to_read)\n",
    "\n",
    "test_score, test_acc, history, num_of_train_samples, num_of_test_sample = create_model_and_apply_on_data(x_train, \n",
    "                                                                                                        y_train,\n",
    "                                                                                                        x_test, \n",
    "                                                                                                        y_test, \n",
    "                                                                                                        max_features,\n",
    "                                                                                                        ID_of_layer_to_repeat = ID_of_layer_to_repeat)\n",
    "print(\"test_score:\",test_score)\n",
    "print(\"test_acc:\" , test_acc)\n",
    "print(\"history:\" , history.history)\n",
    "print(\"num_of_train_samples:\" , num_of_train_samples)\n",
    "print(\"num_of_test_sample:\" , num_of_test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "bUbyz1O5TtEV",
    "outputId": "fe5bdddd-33a3-4b28-94f0-d6de4758ee37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 10)\n",
      "x_test shape: (25000, 10)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 10)          200010    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                19200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 219,275\n",
      "Trainable params: 219,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 16s 653us/step - loss: 0.6015 - acc: 0.6613 - val_loss: 0.5451 - val_acc: 0.7164\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 0.5163 - acc: 0.7428 - val_loss: 0.5393 - val_acc: 0.7214\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 13s 539us/step - loss: 0.4896 - acc: 0.7652 - val_loss: 0.5306 - val_acc: 0.7294\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 14s 568us/step - loss: 0.4741 - acc: 0.7750 - val_loss: 0.5297 - val_acc: 0.7327\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 14s 557us/step - loss: 0.4628 - acc: 0.7802 - val_loss: 0.5289 - val_acc: 0.7295\n",
      "25000/25000 [==============================] - 2s 65us/step\n",
      "Test score: 0.528882891769\n",
      "Test accuracy: 0.72952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.52888289176940917,\n",
       " 0.72951999999999995,\n",
       " <keras.callbacks.History at 0x261d2fd8908>,\n",
       " 25000,\n",
       " 25000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, max_features, maxlen = imdb_lstm_data_preparation(maxlen=10)\n",
    "#my_x_train, my_x_test, my_y_train, my_y_test, my_max_features, my_maxlen = data_preparation_for_sequences_based_deep_models(address_to_read)\n",
    "#x_train, x_test, y_train, y_test, max_features, maxlen = data_preparation_for_sequences_based_deep_models(address_to_read)#imdb_lstm_data_preparation(maxlen=10)\n",
    "create_model_and_apply_on_data(x_train, y_train,x_test, y_test, max_features,embedding_vector_dim = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rhnw6Y4kQbIz"
   },
   "outputs": [],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPT1K2r9RsFo"
   },
   "outputs": [],
   "source": [
    "# `word_to_index` is a mapping (i.e. dict) from words to their index, e.g. `love`: 69\n",
    "words_embeddings = {w:embeddings[idx] for w, idx in word_to_index.items()}\n",
    "\n",
    "# now you can use it like this for example\n",
    "print(words_embeddings['love'])  # possible output: [0.21, 0.56, ..., 0.65, 0.10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhQ1x75KbI19"
   },
   "outputs": [],
   "source": [
    "print(type(score) , type(acc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "imdb_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
