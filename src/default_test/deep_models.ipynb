{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aslesani/pgmpy_fork/blob/master/src/default_test/imdb_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OmJrgoGBTfgJ",
    "outputId": "39d708de-ab42-4288-bee6-7bcc5970b9b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "# Notes\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM, SimpleRNN, GRU\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "\n",
    "from read_write import data_preparation_for_sequences_based_deep_models, convert_binary_classes_to_zero_and_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJSdFzlqcakL"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_train_val_graph(history):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  epochs = range(1, len(loss) + 1)\n",
    "  print('epochs:' , epochs)\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChXfRjq4jJko"
   },
   "outputs": [],
   "source": [
    "def get_max_len_of_sequences(list_of_sequences):\n",
    "  lengths = [len(list_of_sequences[i]) for i in range(len(list_of_sequences))]\n",
    "  return max(lengths) , min(lengths) , lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_zUyBhXljmq"
   },
   "outputs": [],
   "source": [
    "def get_set_of_sensor_events(list_of_sequences):\n",
    " \n",
    "  set_of_sensor_events = set()\n",
    "  \n",
    "  for i in range(len(list_of_sequences)):\n",
    "      set_of_sensor_events = set_of_sensor_events.union(set(list_of_sequences[i]))\n",
    "  \n",
    "  return set_of_sensor_events, len(set_of_sensor_events)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "PSnIdgbbWlm6",
    "outputId": "fafa8eb3-bf07-40db-c168-948bf988ded0"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/aslesani/pgmpy_fork.git\n",
    "#ls\n",
    "#!git clone https://github.com/aslesani/created_dataset.git\n",
    "#!rm -r pgmpy_fork  \n",
    "#cd pgmpy_fork/src/default_test\n",
    "#cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Adhup5wx35Il"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def mcor(y_true, y_pred):\n",
    "    #matthews_correlation\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    " \n",
    " \n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    " \n",
    " \n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    " \n",
    " \n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    " \n",
    " \n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    " \n",
    " \n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w0em365aEiF1",
    "outputId": "c94c0dd6-1e9f-484d-e710-5a7a07f62720"
   },
   "outputs": [],
   "source": [
    "#!pip install tabulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "wRPxCWPzExrc",
    "outputId": "a2e3e2fd-0584-40cc-ac2e-ca74216c0867"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "#print(tabulate([['Alice', 24], ['Bob', 19]], headers=['algorithm', 'acc']))\n",
    "\n",
    "def print_list_of_lists(data , headers):\n",
    "    print(tabulate(data, headers=headers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_print_list_of_lists():\n",
    "    data = [['Alice', 24], ['Bob', 19]]\n",
    "    headers=['algorithm', 'acc']\n",
    "    print_list_of_lists(data , headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm      acc\n",
      "-----------  -----\n",
      "Alice           24\n",
      "Bob             19\n"
     ]
    }
   ],
   "source": [
    "test_print_list_of_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cM2IkLSSM458"
   },
   "outputs": [],
   "source": [
    "def imdb_lstm_data_preparation(max_features = 20000, maxlen = 80):\n",
    "  #max_features = 20000#number_of_events\n",
    "  # cut texts after this number of words (among top max_features most common words)\n",
    "  #maxlen = 10#max_seq_len\n",
    "\n",
    "  print('Loading data...')\n",
    "  (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "  print(len(x_train), 'train sequences')\n",
    "  print(len(x_test), 'test sequences')\n",
    "\n",
    "  #print('before apply pad_sequence, x_train[0]:' , x_train[0])\n",
    "\n",
    "  print('Pad sequences (samples x time)')\n",
    "  x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "  x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "  print('x_train shape:', x_train.shape)\n",
    "  print('x_test shape:', x_test.shape)\n",
    "  \n",
    "  return x_train, x_test, y_train, y_test, max_features, maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Npd2VghtklVO"
   },
   "outputs": [],
   "source": [
    "#! cd pgmpy_fork/src/default_test\n",
    "#!ls\n",
    "#!git clone https://github.com/pgmpy/pgmpy \n",
    "#cd ..\n",
    "#!ls\n",
    "#!cd pgmpy/\n",
    "#pip install -r requirements.txt\n",
    "#!python setup.py install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lstm_without_embedding(x_train, y_train,x_test, y_test, max_features,embedding_vector_dim = 64, batch_size = 32, epochs = 5, \n",
    "                                   loss = 'binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'], plot_train_val_graph = False):\n",
    "  \n",
    "  #batch_size = 32\n",
    "\n",
    "  print('Build model...')\n",
    "  model = Sequential()\n",
    "  #model.add(Embedding(max_features+1, embedding_vector_dim))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  # try using different optimizers and different optimizer configs\n",
    "  model.compile(loss= loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics= metrics)#, mcor,recall, f1])\n",
    "\n",
    "  print('Train...')\n",
    "  history = model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test))\n",
    "  score, acc = model.evaluate(x_test, y_test,\n",
    "                              batch_size=batch_size)\n",
    "  print('Test score:', score)# i think score is loss value\n",
    "  print('Test accuracy:', acc)\n",
    " \n",
    "  if plot_train_val_graph:\n",
    "      plot_train_val_graph(history)\n",
    "      \n",
    "  return score, acc, history, len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsUaDYDeTx3t"
   },
   "outputs": [],
   "source": [
    "def create_model_and_apply_on_data(x_train, y_train,x_test, y_test, max_features,\n",
    "                                   embedding_vector_dim = 64, batch_size = 32, epochs = 1, \n",
    "                                   loss = 'binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'], \n",
    "                                   plot_train_val_graph = False,\n",
    "                                   number_of_lstm_layers = 1,\n",
    "                                   ID_of_layer_to_repeat = 0):\n",
    "  '''\n",
    "  Parameters:\n",
    "  ===============\n",
    "  number_of_lstm_layers (default value = 1)\n",
    "      indicate the number of layers in stack of layers\n",
    "  \n",
    "  ID_of_layer_to_repeat (default value = 0)\n",
    "     0: LSTM\n",
    "     1:RNN\n",
    "     2: GRU\n",
    "  \n",
    "  '''\n",
    "  #batch_size = 32\n",
    "\n",
    "  print('Build model...')\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(max_features+1, embedding_vector_dim))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  #model.add(SimpleRNN(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "  \n",
    "  layer_names = [LSTM, SimpleRNN, GRU]\n",
    "  if number_of_lstm_layers > 1:\n",
    "        for l in range(number_of_lstm_layers-1):\n",
    "            model.add(layer_names[ID_of_layer_to_repeat](64, dropout=0.2, recurrent_dropout=0.2, return_sequences = True))\n",
    "  model.add(layer_names[ID_of_layer_to_repeat](64, dropout=0.2, recurrent_dropout=0.2))\n",
    "        \n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  # try using different optimizers and different optimizer configs\n",
    "  model.compile(loss= loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics= [f1])#metrics, mcor,recall, f1])\n",
    "\n",
    "  print('Train...')\n",
    "  history = model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test))\n",
    "  score, acc = model.evaluate(x_test, y_test,\n",
    "                              batch_size=batch_size)\n",
    "  #print('Test score:', score)# i think score is loss value\n",
    "  #print('Test accuracy:', acc)\n",
    " \n",
    "  #print(model.layers[0].output)\n",
    "  if plot_train_val_graph:\n",
    "      plot_train_val_graph(history)\n",
    "      \n",
    "  return score, acc, history, len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMsynyAJJCnJ"
   },
   "outputs": [],
   "source": [
    "def select_hyperparameters(address_to_read, ID_of_layer_to_repeat, hasActivitycol):\n",
    "    #address_to_read= r\"E:/pgmpy/Seq of sensor events_based on activities/based_on_activities.csv\"\n",
    "    #address_to_read = r\"E:\\pgmpy\\Seq of sensor events_no overlap_based on different deltas\\delta_{}min.csv\"\n",
    "    #address_to_read = r\"E:\\pgmpy\\Seq of sensor events_based_on_activity_and_no_overlap_delta\\delta_{}min.csv\"\n",
    "    \n",
    "    for layers in range(2,5):\n",
    "        print(\"number_of_lstm_layers:\" , layers)\n",
    "\n",
    "        results = []\n",
    "        for delta in list(range(1,10)):# + [30,45,60,75,90,100]:#, 120,150, 180,200,240,300,400,500,600,700,800,900,1000]: #:\n",
    "            print(\"delta:\" , delta)\n",
    "            x_train, x_test, y_train, y_test, max_features, maxlen = data_preparation_for_sequences_based_deep_models(address_to_read = address_to_read.format(delta),\n",
    "                                                                                                                  number_of_words = 122, \n",
    "                                                                                                                  max_seq_len = 20,\n",
    "                                                                                                                  hasActivitycol= hasActivitycol)\n",
    "            test_score, test_acc, history, num_of_train_samples, num_of_test_sample = create_model_and_apply_on_data(x_train =x_train, \n",
    "                                                                                                y_train = y_train,\n",
    "                                                                                                x_test = x_test, \n",
    "                                                                                                y_test = y_test, \n",
    "                                                                                                max_features = max_features,\n",
    "                                                                                                number_of_lstm_layers = layers,\n",
    "                                                                                                ID_of_layer_to_repeat = ID_of_layer_to_repeat )\n",
    "            results.append([delta, \n",
    "                        num_of_train_samples, \n",
    "                        num_of_test_sample, \n",
    "                        history.history['loss'][-1], \n",
    "                        history.history['f1'][-1] ,\n",
    "                        test_score, \n",
    "                        test_acc])#, history.history\n",
    "        #print(history.history)\n",
    "        print_list_of_lists(results, ['delta(min)' ,\n",
    "                                  '#train', \n",
    "                                  '#test', \n",
    "                                  'train loss(last)', \n",
    "                                  'train_f1(last)', \n",
    "                                  'val loss ', \n",
    "                                  'val f1', ])#'history'\n",
    "        print(\"results:\", results)\n",
    "        #print(\"results[:][-1]:\", results[:][-1])\n",
    "        #best_val_acc_index = np.argmax(results[:][-1])\n",
    "        #print(\"****************************************\")\n",
    "        #print(\"best vlidation acc delta:\" , results[best_val_acc_index][0])\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\pgmpy\\Twor2009\\Seq of sensor events_no overlap_based on different deltas\\delta_{}min.csv\n",
      "ID_of_layer_to_repeat: 0\n",
      "number_of_lstm_layers: 2\n",
      "delta: 1\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (11618, 20)\n",
      "x_test shape: (2904, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 11618 samples, validate on 2904 samples\n",
      "Epoch 1/1\n",
      "11618/11618 [==============================] - 18s 2ms/step - loss: 0.2129 - f1: 0.8482 - val_loss: 0.2035 - val_f1: 0.9286\n",
      "2904/2904 [==============================] - 1s 282us/step\n",
      "delta: 2\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (7737, 20)\n",
      "x_test shape: (1934, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 7737 samples, validate on 1934 samples\n",
      "Epoch 1/1\n",
      "7737/7737 [==============================] - 14s 2ms/step - loss: 0.2143 - f1: 0.8686 - val_loss: 0.1557 - val_f1: 0.9543\n",
      "1934/1934 [==============================] - 1s 301us/step\n",
      "delta: 3\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (6047, 20)\n",
      "x_test shape: (1511, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 6047 samples, validate on 1511 samples\n",
      "Epoch 1/1\n",
      "6047/6047 [==============================] - 13s 2ms/step - loss: 0.2224 - f1: 0.8610 - val_loss: 0.1581 - val_f1: 0.9598\n",
      "1511/1511 [==============================] - 0s 327us/step\n",
      "delta: 4\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (5078, 20)\n",
      "x_test shape: (1269, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 5078 samples, validate on 1269 samples\n",
      "Epoch 1/1\n",
      "5078/5078 [==============================] - 12s 2ms/step - loss: 0.2432 - f1: 0.8547 - val_loss: 0.2057 - val_f1: 0.9528\n",
      "1269/1269 [==============================] - 1s 398us/step\n",
      "delta: 5\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (4432, 20)\n",
      "x_test shape: (1107, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 4432 samples, validate on 1107 samples\n",
      "Epoch 1/1\n",
      "4432/4432 [==============================] - 13s 3ms/step - loss: 0.2391 - f1: 0.8622 - val_loss: 0.1269 - val_f1: 0.9799\n",
      "1107/1107 [==============================] - 0s 332us/step\n",
      "delta: 6\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3945, 20)\n",
      "x_test shape: (986, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3945 samples, validate on 986 samples\n",
      "Epoch 1/1\n",
      "3945/3945 [==============================] - 12s 3ms/step - loss: 0.2449 - f1: 0.8449 - val_loss: 0.1728 - val_f1: 0.9636\n",
      "986/986 [==============================] - 0s 326us/step\n",
      "delta: 7\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3573, 20)\n",
      "x_test shape: (893, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3573 samples, validate on 893 samples\n",
      "Epoch 1/1\n",
      "3573/3573 [==============================] - 12s 3ms/step - loss: 0.2614 - f1: 0.8377 - val_loss: 0.1528 - val_f1: 0.9757\n",
      "893/893 [==============================] - 0s 342us/step\n",
      "delta: 8\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3275, 20)\n",
      "x_test shape: (818, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3275 samples, validate on 818 samples\n",
      "Epoch 1/1\n",
      "3275/3275 [==============================] - 12s 4ms/step - loss: 0.2528 - f1: 0.8384 - val_loss: 0.1555 - val_f1: 0.9743\n",
      "818/818 [==============================] - 0s 349us/step\n",
      "delta: 9\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2997, 20)\n",
      "x_test shape: (749, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 73,985\n",
      "Trainable params: 73,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 2997 samples, validate on 749 samples\n",
      "Epoch 1/1\n",
      "2997/2997 [==============================] - 13s 4ms/step - loss: 0.2598 - f1: 0.8389 - val_loss: 0.1543 - val_f1: 0.9730\n",
      "749/749 [==============================] - 0s 364us/step\n",
      "  delta(min)    #train    #test    train loss(last)    train_f1(last)    val loss     val f1\n",
      "------------  --------  -------  ------------------  ----------------  -----------  --------\n",
      "           1     11618     2904            0.212935          0.848218     0.203478  0.928589\n",
      "           2      7737     1934            0.214331          0.868595     0.155691  0.954265\n",
      "           3      6047     1511            0.222396          0.861005     0.158069  0.959838\n",
      "           4      5078     1269            0.243189          0.8547       0.205699  0.952848\n",
      "           5      4432     1107            0.23906           0.86216      0.126918  0.97985\n",
      "           6      3945      986            0.244877          0.844898     0.172806  0.963597\n",
      "           7      3573      893            0.261382          0.837704     0.152763  0.975712\n",
      "           8      3275      818            0.252757          0.838382     0.155514  0.9743\n",
      "           9      2997      749            0.259812          0.838881     0.15427   0.973041\n",
      "results: [[1, 11618, 2904, 0.21293543159144368, 0.8482183167416866, 0.2034779734974958, 0.9285887320507985], [2, 7737, 1934, 0.21433128259957598, 0.8685952958494282, 0.1556906920863506, 0.9542652197189884], [3, 6047, 1511, 0.22239601816621637, 0.8610052856331288, 0.15806904589248208, 0.9598378800619998], [4, 5078, 1269, 0.2431888771868799, 0.8546995019856378, 0.20569929078961094, 0.9528477370410194], [5, 4432, 1107, 0.23905953933024235, 0.8621596855377032, 0.12691832478507317, 0.9798502797141415], [6, 3945, 986, 0.2448765062296194, 0.844898024197616, 0.17280586731089298, 0.9635965606503748], [7, 3573, 893, 0.2613815844284197, 0.8377040802114589, 0.1527628858802133, 0.9757123223077276], [8, 3275, 818, 0.25275737193249564, 0.8383820232362238, 0.15551366814592066, 0.9742997549565322], [9, 2997, 749, 0.2598123715983497, 0.838880936085959, 0.15427007493332964, 0.9730412008288069]]\n",
      "number_of_lstm_layers: 3\n",
      "delta: 1\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (11618, 20)\n",
      "x_test shape: (2904, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 11618 samples, validate on 2904 samples\n",
      "Epoch 1/1\n",
      "11618/11618 [==============================] - 38s 3ms/step - loss: 0.2329 - f1: 0.8366 - val_loss: 0.1907 - val_f1: 0.9399\n",
      "2904/2904 [==============================] - 2s 525us/step\n",
      "delta: 2\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (7737, 20)\n",
      "x_test shape: (1934, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 7737 samples, validate on 1934 samples\n",
      "Epoch 1/1\n",
      "7737/7737 [==============================] - 31s 4ms/step - loss: 0.2316 - f1: 0.8475 - val_loss: 0.2076 - val_f1: 0.9486\n",
      "1934/1934 [==============================] - 1s 531us/step\n",
      "delta: 3\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (6047, 20)\n",
      "x_test shape: (1511, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6047 samples, validate on 1511 samples\n",
      "Epoch 1/1\n",
      "6047/6047 [==============================] - 26s 4ms/step - loss: 0.2487 - f1: 0.8468 - val_loss: 0.1484 - val_f1: 0.9838\n",
      "1511/1511 [==============================] - 1s 538us/step\n",
      "delta: 4\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (5078, 20)\n",
      "x_test shape: (1269, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 5078 samples, validate on 1269 samples\n",
      "Epoch 1/1\n",
      "5078/5078 [==============================] - 28s 6ms/step - loss: 0.2577 - f1: 0.8380 - val_loss: 0.0975 - val_f1: 0.9735\n",
      "1269/1269 [==============================] - 1s 578us/step\n",
      "delta: 5\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (4432, 20)\n",
      "x_test shape: (1107, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_40 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_41 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 4432 samples, validate on 1107 samples\n",
      "Epoch 1/1\n",
      "4432/4432 [==============================] - 26s 6ms/step - loss: 0.2597 - f1: 0.8449 - val_loss: 0.1226 - val_f1: 0.9747\n",
      "1107/1107 [==============================] - 1s 582us/step\n",
      "delta: 6\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3945, 20)\n",
      "x_test shape: (986, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_44 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3945 samples, validate on 986 samples\n",
      "Epoch 1/1\n",
      "3945/3945 [==============================] - 25s 6ms/step - loss: 0.2572 - f1: 0.8413 - val_loss: 0.2405 - val_f1: 0.9354\n",
      "986/986 [==============================] - 1s 594us/step\n",
      "delta: 7\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3573, 20)\n",
      "x_test shape: (893, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_48 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3573 samples, validate on 893 samples\n",
      "Epoch 1/1\n",
      "3573/3573 [==============================] - 29s 8ms/step - loss: 0.2669 - f1: 0.8371 - val_loss: 0.2547 - val_f1: 0.9389\n",
      "893/893 [==============================] - 0s 536us/step\n",
      "delta: 8\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3275, 20)\n",
      "x_test shape: (818, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_50 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_51 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3275 samples, validate on 818 samples\n",
      "Epoch 1/1\n",
      "3275/3275 [==============================] - 29s 9ms/step - loss: 0.2763 - f1: 0.8355 - val_loss: 0.1364 - val_f1: 0.9742\n",
      "818/818 [==============================] - 0s 555us/step\n",
      "delta: 9\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2997, 20)\n",
      "x_test shape: (749, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_52 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_53 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_54 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 107,009\n",
      "Trainable params: 107,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 2997 samples, validate on 749 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2997/2997 [==============================] - 27s 9ms/step - loss: 0.2689 - f1: 0.8505 - val_loss: 0.1675 - val_f1: 0.9701\n",
      "749/749 [==============================] - 0s 480us/step\n",
      "  delta(min)    #train    #test    train loss(last)    train_f1(last)    val loss     val f1\n",
      "------------  --------  -------  ------------------  ----------------  -----------  --------\n",
      "           1     11618     2904            0.232903          0.83656     0.190687   0.939949\n",
      "           2      7737     1934            0.231587          0.847535    0.207567   0.948622\n",
      "           3      6047     1511            0.248652          0.846826    0.148357   0.983757\n",
      "           4      5078     1269            0.257695          0.838024    0.0975071  0.973467\n",
      "           5      4432     1107            0.259715          0.844936    0.122578   0.974736\n",
      "           6      3945      986            0.257234          0.841289    0.240519   0.935391\n",
      "           7      3573      893            0.266941          0.837111    0.254727   0.938874\n",
      "           8      3275      818            0.276347          0.835509    0.136448   0.974166\n",
      "           9      2997      749            0.268868          0.850522    0.167523   0.97009\n",
      "results: [[1, 11618, 2904, 0.23290255291005546, 0.8365601887902411, 0.19068729239913632, 0.9399490251357233], [2, 7737, 1934, 0.23158665367999065, 0.8475350483498926, 0.20756666620301453, 0.9486219826257463], [3, 6047, 1511, 0.2486519647251777, 0.8468256547408832, 0.14835667389510956, 0.9837570291414394], [4, 5078, 1269, 0.25769454998475166, 0.8380237516806603, 0.09750712779479012, 0.9734670430116525], [5, 4432, 1107, 0.2597154935734474, 0.8449360943443078, 0.12257812364832872, 0.9747355339649894], [6, 3945, 986, 0.2572341518823638, 0.841289127265848, 0.24051926534010842, 0.9353909057245777], [7, 3573, 893, 0.26694063625431114, 0.8371106676450805, 0.25472674259346517, 0.9388738677055811], [8, 3275, 818, 0.276346946396218, 0.8355092332563328, 0.13644840047309917, 0.9741658791353184], [9, 2997, 749, 0.26886762372843614, 0.8505221423722523, 0.16752261269554117, 0.9700900104558356]]\n",
      "number_of_lstm_layers: 4\n",
      "delta: 1\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (11618, 20)\n",
      "x_test shape: (2904, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_56 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_58 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 11618 samples, validate on 2904 samples\n",
      "Epoch 1/1\n",
      "11618/11618 [==============================] - 64s 6ms/step - loss: 0.2412 - f1: 0.8152 - val_loss: 0.1884 - val_f1: 0.9593\n",
      "2904/2904 [==============================] - 2s 827us/step\n",
      "delta: 2\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (7737, 20)\n",
      "x_test shape: (1934, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_61 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_62 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 7737 samples, validate on 1934 samples\n",
      "Epoch 1/1\n",
      "7737/7737 [==============================] - 145s 19ms/step - loss: 0.2427 - f1: 0.8445 - val_loss: 0.2045 - val_f1: 0.9420\n",
      "1934/1934 [==============================] - 1s 751us/step\n",
      "delta: 3\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (6047, 20)\n",
      "x_test shape: (1511, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_64 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_66 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 6047 samples, validate on 1511 samples\n",
      "Epoch 1/1\n",
      "6047/6047 [==============================] - 60s 10ms/step - loss: 0.2681 - f1: 0.8079 - val_loss: 0.1476 - val_f1: 0.9711\n",
      "1511/1511 [==============================] - 1s 771us/step\n",
      "delta: 4\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (5078, 20)\n",
      "x_test shape: (1269, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_68 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_69 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_70 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 5078 samples, validate on 1269 samples\n",
      "Epoch 1/1\n",
      "5078/5078 [==============================] - 52s 10ms/step - loss: 0.2811 - f1: 0.8033 - val_loss: 0.1808 - val_f1: 0.9538\n",
      "1269/1269 [==============================] - 1s 786us/step\n",
      "delta: 5\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (4432, 20)\n",
      "x_test shape: (1107, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_71 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_72 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_73 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_74 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4432 samples, validate on 1107 samples\n",
      "Epoch 1/1\n",
      "4432/4432 [==============================] - 44s 10ms/step - loss: 0.2772 - f1: 0.8313 - val_loss: 0.1570 - val_f1: 0.9645\n",
      "1107/1107 [==============================] - 1s 755us/step\n",
      "delta: 6\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3945, 20)\n",
      "x_test shape: (986, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_75 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_76 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_77 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_78 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3945 samples, validate on 986 samples\n",
      "Epoch 1/1\n",
      "3945/3945 [==============================] - 794s 201ms/step - loss: 0.2993 - f1: 0.8146 - val_loss: 0.1966 - val_f1: 0.9671\n",
      "986/986 [==============================] - 1s 881us/step\n",
      "delta: 7\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3573, 20)\n",
      "x_test shape: (893, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_79 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_80 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_81 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_82 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3573 samples, validate on 893 samples\n",
      "Epoch 1/1\n",
      "3573/3573 [==============================] - 69s 19ms/step - loss: 0.3012 - f1: 0.8065 - val_loss: 0.3578 - val_f1: 0.8923\n",
      "893/893 [==============================] - 1s 886us/step\n",
      "delta: 8\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (3275, 20)\n",
      "x_test shape: (818, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_83 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_84 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_85 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_86 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 3275 samples, validate on 818 samples\n",
      "Epoch 1/1\n",
      "3275/3275 [==============================] - 66s 20ms/step - loss: 0.3044 - f1: 0.7943 - val_loss: 0.2028 - val_f1: 0.9635\n",
      "818/818 [==============================] - 1s 1ms/step\n",
      "delta: 9\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2997, 20)\n",
      "x_test shape: (749, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_87 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_88 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_89 (LSTM)               (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "lstm_90 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 140,033\n",
      "Trainable params: 140,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 2997 samples, validate on 749 samples\n",
      "Epoch 1/1\n",
      "2997/2997 [==============================] - 54s 18ms/step - loss: 0.3027 - f1: 0.8127 - val_loss: 0.2003 - val_f1: 0.9655\n",
      "749/749 [==============================] - 1s 924us/step\n",
      "  delta(min)    #train    #test    train loss(last)    train_f1(last)    val loss     val f1\n",
      "------------  --------  -------  ------------------  ----------------  -----------  --------\n",
      "           1     11618     2904            0.24116           0.81516      0.188382  0.959292\n",
      "           2      7737     1934            0.242652          0.844508     0.204526  0.94199\n",
      "           3      6047     1511            0.268099          0.80792      0.1476    0.971087\n",
      "           4      5078     1269            0.281091          0.803258     0.18077   0.953814\n",
      "           5      4432     1107            0.277173          0.831329     0.157046  0.964506\n",
      "           6      3945      986            0.299317          0.814553     0.196566  0.967083\n",
      "           7      3573      893            0.301184          0.806525     0.357819  0.892296\n",
      "           8      3275      818            0.30437           0.79425      0.202836  0.963488\n",
      "           9      2997      749            0.302683          0.812692     0.200308  0.965483\n",
      "results: [[1, 11618, 2904, 0.24116029509853518, 0.8151595189149049, 0.1883820455198076, 0.9592923677985662], [2, 7737, 1934, 0.24265243434869027, 0.8445077484563384, 0.20452603998939742, 0.9419895584358917], [3, 6047, 1511, 0.2680988580565108, 0.8079200921146183, 0.14760017474406922, 0.9710873137397691], [4, 5078, 1269, 0.28109089307437124, 0.8032583875795104, 0.18076999394488766, 0.9538141555726012], [5, 4432, 1107, 0.277173071454148, 0.8313290973863017, 0.15704606206248015, 0.9645061131092268], [6, 3945, 986, 0.29931682075157817, 0.8145530596734302, 0.19656558384321646, 0.9670834415582807], [7, 3573, 893, 0.3011837135817936, 0.806524752169272, 0.3578187897717966, 0.8922956263498389], [8, 3275, 818, 0.3043699261591635, 0.7942500439126983, 0.20283631714457112, 0.9634876041365719], [9, 2997, 749, 0.3026834712809708, 0.8126915490026668, 0.2003084326956237, 0.9654831676203036]]\n"
     ]
    }
   ],
   "source": [
    "#address_to_read, hasActivitycol= r\"E:/pgmpy\\Twor2009\\Seq of sensor events_based on activities\\based_on_activities.csv\", True\n",
    "address_to_read, hasActivitycol = r\"E:\\pgmpy\\Twor2009\\Seq of sensor events_no overlap_based on different deltas\\delta_{}min.csv\", False\n",
    "#address_to_read, hasActivitycol = r\"E:\\pgmpy\\Twor2009\\Seq of sensor events_based_on_activity_and_no_overlap_delta\\delta_{}min.csv\", True\n",
    "print(address_to_read)\n",
    "ID_of_layer_to_repeat = 0\n",
    "print(\"ID_of_layer_to_repeat:\" , ID_of_layer_to_repeat)\n",
    "results = select_hyperparameters(address_to_read = address_to_read , \n",
    "                                 ID_of_layer_to_repeat = ID_of_layer_to_repeat, \n",
    "                                 hasActivitycol = hasActivitycol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d20da67344a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(results[:][-1])\n",
    "print(np.argmax(results[:][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (3, 20)\n",
      "x_test shape: (0, 20)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 64)          7872      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 40,961\n",
      "Trainable params: 40,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e900f81b9e88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                                                                                         \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                                                                                                         \u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                                                                                                         ID_of_layer_to_repeat = ID_of_layer_to_repeat)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_score:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_acc:\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-b17a894e2105>\u001b[0m in \u001b[0;36mcreate_model_and_apply_on_data\u001b[1;34m(x_train, y_train, x_test, y_test, max_features, embedding_vector_dim, batch_size, epochs, loss, optimizer, metrics, plot_train_val_graph, number_of_lstm_layers, ID_of_layer_to_repeat)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             validation_data=(x_test, y_test))\n\u001b[0m\u001b[0;32m     47\u001b[0m   score, acc = model.evaluate(x_test, y_test,\n\u001b[0;32m     48\u001b[0m                               batch_size=batch_size)\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m                 \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m                 batch_size=batch_size)\n\u001b[0m\u001b[0;32m    973\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mval_ins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37_64\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     78\u001b[0m                              'for each key in: ' + str(names))\n\u001b[0;32m     79\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "address_to_read= r\"E:/pgmpy/Test2/Seq of sensor events_based on activities/based_on_activities.csv\"\n",
    "\n",
    "x_train, x_test, y_train, y_test, max_features, maxlen = data_preparation_for_sequences_based_deep_models(address_to_read,\n",
    "                                                                                                         number_of_words = 122, \n",
    "                                                                                                        max_seq_len = 20,\n",
    "                                                                                                         hasActivitycol = True)\n",
    "ID_of_layer_to_repeat = 0\n",
    "test_score, test_acc, history, num_of_train_samples, num_of_test_sample = create_model_and_apply_on_data(x_train, \n",
    "                                                                                                        y_train,\n",
    "                                                                                                        x_test, \n",
    "                                                                                                        y_test, \n",
    "                                                                                                        max_features,\n",
    "                                                                                                        ID_of_layer_to_repeat = ID_of_layer_to_repeat)\n",
    "print(\"test_score:\",test_score)\n",
    "print(\"test_acc:\" , test_acc)\n",
    "print(\"history:\" , history.history)\n",
    "print(\"num_of_train_samples:\" , num_of_train_samples)\n",
    "print(\"num_of_test_sample:\" , num_of_test_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "bUbyz1O5TtEV",
    "outputId": "fe5bdddd-33a3-4b28-94f0-d6de4758ee37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 10)\n",
      "x_test shape: (25000, 10)\n",
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 10)          200010    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                19200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 219,275\n",
      "Trainable params: 219,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 16s 653us/step - loss: 0.6015 - acc: 0.6613 - val_loss: 0.5451 - val_acc: 0.7164\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 13s 529us/step - loss: 0.5163 - acc: 0.7428 - val_loss: 0.5393 - val_acc: 0.7214\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 13s 539us/step - loss: 0.4896 - acc: 0.7652 - val_loss: 0.5306 - val_acc: 0.7294\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 14s 568us/step - loss: 0.4741 - acc: 0.7750 - val_loss: 0.5297 - val_acc: 0.7327\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 14s 557us/step - loss: 0.4628 - acc: 0.7802 - val_loss: 0.5289 - val_acc: 0.7295\n",
      "25000/25000 [==============================] - 2s 65us/step\n",
      "Test score: 0.528882891769\n",
      "Test accuracy: 0.72952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.52888289176940917,\n",
       " 0.72951999999999995,\n",
       " <keras.callbacks.History at 0x261d2fd8908>,\n",
       " 25000,\n",
       " 25000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, max_features, maxlen = imdb_lstm_data_preparation(maxlen=10)\n",
    "#my_x_train, my_x_test, my_y_train, my_y_test, my_max_features, my_maxlen = data_preparation_for_sequences_based_deep_models(address_to_read)\n",
    "#x_train, x_test, y_train, y_test, max_features, maxlen = data_preparation_for_sequences_based_deep_models(address_to_read)#imdb_lstm_data_preparation(maxlen=10)\n",
    "create_model_and_apply_on_data(x_train, y_train,x_test, y_test, max_features,embedding_vector_dim = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rhnw6Y4kQbIz"
   },
   "outputs": [],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPT1K2r9RsFo"
   },
   "outputs": [],
   "source": [
    "# `word_to_index` is a mapping (i.e. dict) from words to their index, e.g. `love`: 69\n",
    "words_embeddings = {w:embeddings[idx] for w, idx in word_to_index.items()}\n",
    "\n",
    "# now you can use it like this for example\n",
    "print(words_embeddings['love'])  # possible output: [0.21, 0.56, ..., 0.65, 0.10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhQ1x75KbI19"
   },
   "outputs": [],
   "source": [
    "print(type(score) , type(acc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "imdb_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
